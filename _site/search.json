[
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "title": "Take-home Exercise 4: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "",
    "text": "In Singapore’s ever-changing rental market, understanding the factors influencing rental prices is crucial for tenants and landlords alike. This study focuses on three key aspects: descriptive analysis, correlation analysis, and clustering analysis.\n\n\nDetermine the correlation between rental prices and various numerical variables, such as property size and proximity to amenities, and analyze their relationships.\nUtilize clustering analysis to discern distinct groups within the rental market based on property characteristics, such as size, amenities proximity, and other relevant factors, aiming to uncover patterns and insights into different market segments or tenant preferences."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#overview",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#overview",
    "title": "Take-home Exercise 4: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "",
    "text": "In Singapore’s ever-changing rental market, understanding the factors influencing rental prices is crucial for tenants and landlords alike. This study focuses on three key aspects: descriptive analysis, correlation analysis, and clustering analysis.\n\n\nDetermine the correlation between rental prices and various numerical variables, such as property size and proximity to amenities, and analyze their relationships.\nUtilize clustering analysis to discern distinct groups within the rental market based on property characteristics, such as size, amenities proximity, and other relevant factors, aiming to uncover patterns and insights into different market segments or tenant preferences."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#loading-r-packages",
    "title": "Take-home Exercise 4: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "\n2 Loading R packages",
    "text": "2 Loading R packages\nThe original design will then be remade using data visualization design principles and best practices using ggplot2, its extensions, and tidyverse packages.\n\npacman::p_load(poLCA, ggplot2, plotly, tidyverse, corrplot)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#dataset",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#dataset",
    "title": "Take-home Exercise 4: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "\n3 Dataset",
    "text": "3 Dataset\nThe data on rental transactions was collected from the Urban Redevelopment Authority’s (URA) REALIS database.\nThe study utilized rental transaction data from 01 January 2021 to 31 December 2022, sourced from IRAS via URA. It includes rental prices, commencement dates, building names, addresses, and planning regions. Zoning and postal district information were omitted as they duplicated planning area data.\n\nRental_data &lt;- read_csv(\"../../data/ResidentialRental_Final.csv\")\n\nTo ensure there are no missing values in the processed data, check it as follows.\n\nsum(is.na(Rental_data))\n\n[1] 0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#descriptive-analysis",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#descriptive-analysis",
    "title": "Take-home Exercise 4: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "\n4 Descriptive Analysis",
    "text": "4 Descriptive Analysis\n\nClick to view the code.ggplot(Rental_data, aes(x=`Planning_Region`, y= `Monthly_Rent_SGD`, fill=`Property_Type`)) +\n  geom_boxplot() +\n  facet_wrap(~`Planning_Region`, scales = \"free\") +\n  labs(x=\"Planning Region\", y=\"Monthly Rent\")\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(Rental_data, aes(x=`Planning_Region`, y= `Monthly_Rent_SGD`)) +\n  geom_boxplot() +\n  facet_wrap(~`Property_Type`, scales = \"free\") +\n  labs(x=\"Planning Region\", y=\"Monthly Rent\") +\n  theme(axis.text.x = element_text(angle = 90))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#correlation-analysis",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#correlation-analysis",
    "title": "Take-home Exercise 4: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "\n5 Correlation Analysis",
    "text": "5 Correlation Analysis\nPlotting a correlation matrix of the various numerical variables, we observe that the correlations between monthly rent and variables measuring proximity are fairly week ranging between 0.3 to -0.3. Rental prices were most strongly correlated with the size of the unit.\n\nClick to view the code.numerical_data &lt;- Rental_data[, sapply(Rental_data, is.numeric)]\n\nnumerical_data &lt;- numerical_data[, -1]\n\ncorrelation_matrix &lt;- cor(numerical_data)\ncorrplot(correlation_matrix, method = \"circle\")\n\n\n\n\n\n\n\n\npairs(~Monthly_Rent_SGD + Floor_Area_SQM_Avg + Floor_Area_SQFT_Avg + distance_to_mrt, data = Rental_data,\n      main = \"Scatterplot Matrix\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#clustering-analysis",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#clustering-analysis",
    "title": "Take-home Exercise 4: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "\n6 Clustering Analysis",
    "text": "6 Clustering Analysis\n\n6.1 Data Preparation\n\nExclude columns that are either irrelevant or similar, such as retaining only “Monthly_Rent_PSF” instead of both “Monthly_Rent_PSM” and “Monthly_Rent_PSF”.\nBin continuous variables into categories of relatively similar sizes and assign labels to each category.\n\n\nClick to view the code.df_clustering &lt;- Rental_data %&gt;%\n  select(-Column1, -Project_Name, -Street_Name, -Postal_District, -Monthly_Rent_PSM, -Floor_Area_SQM_Avg, -Lease_Commencement_Date, -nearest_mrt, -nearest_school, -latitude, -longitude) %&gt;%\n  mutate(Monthly_Rent_SGD = cut(Monthly_Rent_SGD,\n                             breaks = c(0,2000,3000,4000,5000,Inf),\n                             labels = c(\"0-2k\", \"2-3k\", \"3-4k\", \"4-5k\", \"5k+\"))) %&gt;%\n  mutate(Monthly_Rent_PSF = cut(Monthly_Rent_PSF,\n                             breaks = c(0,3,4,Inf),\n                             labels = c(\"0-3\", \"3-4\", \"4+\"))) %&gt;%\n  mutate(Floor_Area_SQFT_Avg = cut(Floor_Area_SQFT_Avg,\n                             breaks = c(0,600,1000,1400,Inf),\n                             labels = c(\"0-600\", \"600-1000\", \"1000-1400\", \"1400+\"))) %&gt;%\n  mutate(distance_to_mrt = cut(distance_to_mrt,\n                             breaks = c(0,0.3,0.6,0.9,Inf),\n                             labels = c(\"0-0.3\", \"0.3-0.6\", \"0.6-0.9\", \"0.9+\"))) %&gt;%\n  mutate(distance_to_school = cut(distance_to_school,\n                             breaks = c(0,0.3,0.5,0.7,Inf),\n                             labels = c(\"0-0.3\", \"0.3-0.5\", \"0.5-0.7\", \"0.7+\")))\n\nprint(df_clustering)\n\n# A tibble: 192,199 × 8\n    Year Planning_Region Property_Type         Monthly_Rent_SGD Monthly_Rent_PSF\n   &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;                 &lt;fct&gt;            &lt;fct&gt;           \n 1  2021 East Region     Non-landed Properties 0-2k             3-4             \n 2  2021 North Region    Executive Condominium 2-3k             0-3             \n 3  2021 West Region     Non-landed Properties 2-3k             0-3             \n 4  2021 Central Region  Non-landed Properties 3-4k             3-4             \n 5  2021 East Region     Non-landed Properties 2-3k             0-3             \n 6  2021 Central Region  Non-landed Properties 4-5k             3-4             \n 7  2021 Central Region  Non-landed Properties 3-4k             0-3             \n 8  2021 Central Region  Non-landed Properties 3-4k             3-4             \n 9  2021 East Region     Non-landed Properties 0-2k             0-3             \n10  2021 Central Region  Non-landed Properties 3-4k             4+              \n# ℹ 192,189 more rows\n# ℹ 3 more variables: Floor_Area_SQFT_Avg &lt;fct&gt;, distance_to_mrt &lt;fct&gt;,\n#   distance_to_school &lt;fct&gt;\n\n\nAfter completing the data cleaning process, all variables are transformed into categorical factors and verified to ensure there are no missing values.\n\nClick to view the code.categorical_vars &lt;- c(\"Year\", \"Planning_Region\", \"Property_Type\", \"Monthly_Rent_SGD\", \"Monthly_Rent_PSF\", \"Floor_Area_SQFT_Avg\", \"distance_to_mrt\", \"distance_to_school\")\ndf_clustering[categorical_vars] &lt;- lapply(df_clustering[categorical_vars], factor)\n\nsapply(df_clustering, function(x) sum(is.na(x)))\n\n               Year     Planning_Region       Property_Type    Monthly_Rent_SGD \n                  0                   0                   0                   0 \n   Monthly_Rent_PSF Floor_Area_SQFT_Avg     distance_to_mrt  distance_to_school \n                  0                   0                   0                   0 \n\n\n\n6.2 Model and Result\nRun the model by specifying the desired number of classes(7) and the number of repetitions(5).\nIf we perform more than one repetition, it indicates that we conducted a comprehensive search to find the lowest BIC score, ensuring the model’s robustness and accuracy in determining the optimal number of classes.\n\nClick to view the code.set.seed(1234)\n\nf &lt;- as.formula(cbind(Year, Planning_Region, Property_Type, Monthly_Rent_SGD, Monthly_Rent_PSF, Floor_Area_SQFT_Avg, distance_to_mrt, distance_to_school) ~ 1)\n\nLCA_model &lt;- poLCA(f, df_clustering, nclass = 7, nrep = 5, maxiter = 5000)\n\nModel 1: llik = -1547810 ... best llik = -1547810\nModel 2: llik = -1548973 ... best llik = -1547810\nModel 3: llik = -1546851 ... best llik = -1546851\nModel 4: llik = -1547142 ... best llik = -1546851\nModel 5: llik = -1546851 ... best llik = -1546851\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$Year\n           Pr(1)  Pr(2)\nclass 1:  0.4577 0.5423\nclass 2:  0.3235 0.6765\nclass 3:  0.5960 0.4040\nclass 4:  0.6658 0.3342\nclass 5:  0.6861 0.3139\nclass 6:  0.5486 0.4514\nclass 7:  0.4127 0.5873\n\n$Planning_Region\n           Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)\nclass 1:  0.3788 0.2676 0.1338 0.0276 0.1922\nclass 2:  0.6706 0.1337 0.0847 0.0078 0.1032\nclass 3:  0.3310 0.3404 0.1773 0.0302 0.1210\nclass 4:  0.1401 0.3621 0.1641 0.0665 0.2673\nclass 5:  0.1854 0.3656 0.2176 0.0610 0.1703\nclass 6:  0.4173 0.2434 0.1598 0.0395 0.1400\nclass 7:  0.8433 0.0870 0.0168 0.0009 0.0521\n\n$Property_Type\n           Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)\nclass 1:  0.0000 0.0355 0.9607 0.0012 0.0026\nclass 2:  0.0000 0.0007 0.9979 0.0000 0.0014\nclass 3:  0.0000 0.0001 0.9995 0.0000 0.0004\nclass 4:  0.0002 0.0706 0.9149 0.0029 0.0115\nclass 5:  0.0000 0.0131 0.9831 0.0004 0.0035\nclass 6:  0.0991 0.0047 0.5520 0.1395 0.2047\nclass 7:  0.0042 0.0011 0.9742 0.0052 0.0152\n\n$Monthly_Rent_SGD\n           Pr(1)  Pr(2)  Pr(3)  Pr(4)  Pr(5)\nclass 1:  0.0000 0.0000 0.6513 0.3487 0.0000\nclass 2:  0.0000 0.1064 0.5555 0.2500 0.0881\nclass 3:  0.2962 0.7038 0.0000 0.0000 0.0000\nclass 4:  0.0240 0.5309 0.4443 0.0009 0.0000\nclass 5:  0.0918 0.9082 0.0000 0.0000 0.0000\nclass 6:  0.0018 0.0188 0.1190 0.2867 0.5738\nclass 7:  0.0000 0.0000 0.0000 0.0995 0.9005\n\n$Monthly_Rent_PSF\n           Pr(1)  Pr(2)  Pr(3)\nclass 1:  0.0000 0.9302 0.0698\nclass 2:  0.0000 0.0000 1.0000\nclass 3:  0.0047 0.1997 0.7956\nclass 4:  1.0000 0.0000 0.0000\nclass 5:  0.3909 0.5636 0.0455\nclass 6:  0.7863 0.1910 0.0226\nclass 7:  0.0000 0.2924 0.7076\n\n$Floor_Area_SQFT_Avg\n           Pr(1)  Pr(2)  Pr(3)  Pr(4)\nclass 1:  0.0000 0.3034 0.6966 0.0000\nclass 2:  0.2216 0.7784 0.0000 0.0000\nclass 3:  1.0000 0.0000 0.0000 0.0000\nclass 4:  0.0000 0.0000 0.8052 0.1948\nclass 5:  0.0000 1.0000 0.0000 0.0000\nclass 6:  0.0000 0.0000 0.0000 1.0000\nclass 7:  0.0000 0.0068 0.3896 0.6035\n\n$distance_to_mrt\n           Pr(1)  Pr(2)  Pr(3)  Pr(4)\nclass 1:  0.2058 0.3333 0.2035 0.2574\nclass 2:  0.3642 0.3708 0.1327 0.1324\nclass 3:  0.2130 0.3904 0.1556 0.2410\nclass 4:  0.1353 0.2572 0.2548 0.3527\nclass 5:  0.1407 0.3098 0.2012 0.3483\nclass 6:  0.0708 0.2126 0.4026 0.3140\nclass 7:  0.2002 0.3984 0.2240 0.1774\n\n$distance_to_school\n           Pr(1)  Pr(2)  Pr(3)  Pr(4)\nclass 1:  0.2121 0.3309 0.2251 0.2319\nclass 2:  0.1764 0.2652 0.2517 0.3067\nclass 3:  0.1952 0.3924 0.2139 0.1986\nclass 4:  0.2037 0.3781 0.1819 0.2363\nclass 5:  0.1916 0.4133 0.2005 0.1946\nclass 6:  0.1182 0.4297 0.1727 0.2794\nclass 7:  0.1091 0.2524 0.1973 0.4412\n\nEstimated class population shares \n 0.1299 0.1655 0.1393 0.1574 0.1349 0.1184 0.1546 \n \nPredicted class memberships (by modal posterior prob.) \n 0.1293 0.1645 0.145 0.1607 0.1341 0.1105 0.156 \n \n========================================================= \nFit for 7 latent classes: \n========================================================= \nnumber of observations: 192199 \nnumber of estimated parameters: 174 \nresidual degrees of freedom: 47825 \nmaximum log-likelihood: -1546851 \n \nAIC(7): 3094050\nBIC(7): 3095819\nG^2(7): 193628.3 (Likelihood ratio/deviance statistic) \nX^2(7): 434072.2 (Chi-square goodness of fit) \n \n\n\n\n6.3 Plot BIC score\n\nClick to view the code.LCA_model$bic\n\n[1] 3095819\n\n\n\n6.4 Plot AIC score\n\nClick to view the code.LCA_model$aic\n\n[1] 3094050\n\n\n\n6.5 Plot Entropy\n\nClick to view the code.entropy &lt;- function(p) sum(-p*log(p))\nerror_prior &lt;- entropy(LCA_model$P)\nerror_post &lt;- mean(apply(LCA_model$posterior, c(1,2), entropy), na.rm=T)\nLCA_entropy &lt;- (error_prior - error_post) / error_prior\nLCA_entropy\n\n[1] 0.9846065"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#visualising-results",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#visualising-results",
    "title": "Take-home Exercise 4: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "\n7 Visualising Results",
    "text": "7 Visualising Results\nThe classification obtained from the model is added to the initial dataset to facilitate the comparison of variables across different classes for plotting purposes.\n\nClick to view the code.df_clustering$class &lt;- LCA_model$predclass\ndf_clustering$class &lt;- factor(df_clustering$class)\n\n\n\nClick to view the code.plot_table &lt;- df_clustering %&gt;%\n  group_by(Planning_Region, class) %&gt;%\n  summarise(counts = n()) %&gt;% \n  ungroup\n\np1 &lt;- ggplot(plot_table, aes(fill = Planning_Region, y = counts, x = class)) + \n  geom_bar(position = \"fill\", stat = \"identity\")\n\nggplotly(p1)\n\n\n\n\n\n\nClick to view the code.p2 &lt;- ggplot(plot_table, aes(fill = class, y = counts, x = Planning_Region)) + \n  geom_bar(position = \"fill\", stat = \"identity\")\n\nggplotly(p2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#ui-design",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#ui-design",
    "title": "Take-home Exercise 4: Prototyping Modules for Visual Analytics Shiny Application",
    "section": "\n8 UI Design",
    "text": "8 UI Design\nClick here to view the shinyapp of this exercise.\n\nClick to view the code.pacman::p_load(shiny, tidyverse, shinydashboard)\n\nvisualdata &lt;- read_csv(\"data/ResidentialRental_Final.csv\")\n\nui &lt;- dashboardPage(\n  dashboardHeader(title = 'Rental market learning and valuation', titleWidth = 400),\n  dashboardSidebar(width = 400,\n                   sidebarMenu(id = 'a',\n                               menuItem('Historical data', tabName = 'historical', icon = icon(\"search\")),\n                               menuItem('Statistics', tabName = 'Statistics', icon = icon(\"line-chart\"))\n                   )\n  ),\n  dashboardBody(\n    tabItems(\n      #——————————————————————————————————————————————————————————————————————Historical data\n      tabItem(tabName = \"historical\",\n              fluidPage(\n                titlePanel(\"Places to Rent\"),\n                selectInput(\"region\", \"Planning Region\", choices = unique(visualdata$Planning_Region)),\n                selectInput(\"type\", \"Property Type\", choices = NULL),\n                tableOutput(\"data\")\n              )\n      ),\n      tabItem(tabName = \"Statistics\",\n              fluidPage(\n                titlePanel(\"Statistics\"),\n                fluidRow(\n                  column(width = 12,\n                         tabsetPanel(\n                           #——————————————————————————————————————————————————————————————————————Barchart\n                           tabPanel(\"Bar Chart\",\n                                    box(\n                                      radioButtons('xcol1',\n                                                   label = tags$strong('Analyse Sales By:'),\n                                                   choices = c('Property Type' = 'Property_Type',\n                                                               'Planning Region' = 'Planning_Region'),\n                                                   inline = TRUE)\n                                    ),\n                                    box(\n                                      width = 12,\n                                      height = 800,\n                                      solidHeader = TRUE,\n                                      collapsible = FALSE,\n                                      collapsed = FALSE,\n                                      plotOutput('barchart', height = 750)\n                                    )\n                           ),\n                           #——————————————————————————————————————————————————————————————————————Boxplot1\n                           tabPanel(\"Boxplot1\", \n                                    box(\n                                      width = 12,\n                                      height = 800,\n                                      solidHeader = TRUE,\n                                      collapsible = FALSE,\n                                      collapsed = FALSE,\n                                      plotOutput('Boxplot1', height = 750)\n                                    )\n                           ),\n                           #——————————————————————————————————————————————————————————————————————Boxplot2\n                           tabPanel(\"Boxplot2\", \n                                    box(\n                                      width = 12,\n                                      height = 800,\n                                      solidHeader = TRUE,\n                                      collapsible = FALSE,\n                                      collapsed = FALSE,\n                                      plotOutput('Boxplot2', height = 750)\n                                    )\n                           ),\n                           #——————————————————————————————————————————————————————————————————————Boxplot3\n                           tabPanel(\"Boxplot3\", \n                                    box(\n                                      width = 12,\n                                      height = 800,\n                                      solidHeader = TRUE,\n                                      collapsible = FALSE,\n                                      collapsed = FALSE,\n                                      plotOutput('Boxplot3', height = 750)\n                                    )\n                           ),\n                           #——————————————————————————————————————————————————————————————————————scatterplot1\n                           tabPanel(\"Scatterplot1\", \n                                    box(\n                                      width = 12,\n                                      height = 800,\n                                      solidHeader = TRUE,\n                                      collapsible = FALSE,\n                                      collapsed = FALSE,\n                                      plotOutput('Scatterplot1', height = 750)\n                                    )\n                           ),\n                           #——————————————————————————————————————————————————————————————————————scatterplot2\n                           tabPanel(\"Scatterplot2\", \n                                    box(\n                                      width = 12,\n                                      height = 800,\n                                      solidHeader = TRUE,\n                                      collapsible = FALSE,\n                                      collapsed = FALSE,\n                                      plotOutput('Scatterplot2', height = 750)\n                                    )\n                           ),\n                           #——————————————————————————————————————————————————————————————————————scatterplot3\n                           tabPanel(\"Scatterplot3\", \n                                    box(\n                                      width = 12,\n                                      height = 800,\n                                      solidHeader = TRUE,\n                                      collapsible = FALSE,\n                                      collapsed = FALSE,\n                                      plotOutput('Scatterplot3', height = 750)\n                                    )\n                           ),\n                           #——————————————————————————————————————————————————————————————————————scatterplot matrix\n                           tabPanel(\"Scatterplot matrix\", \n                                    box(\n                                      width = 12,\n                                      height = 800,\n                                      solidHeader = TRUE,\n                                      collapsible = FALSE,\n                                      collapsed = FALSE,\n                                      plotOutput('matrix', height = 750)\n                                    )\n                           )\n                         ), #tabsetPanel(\n                  ) #column(\n                ) #fluidRow(\n              ), #fluidPage(\n      )\n    ) #tabItems(\n  ) #dashboardBody(\n) #dashboardPage(\n\n\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output){\n  #——————————————————————————————————————————————————————————————————————historical\n  region &lt;- reactive({\n    filter(visualdata, Planning_Region == input$region)\n  })\n  observeEvent(region(), {\n    choices &lt;- unique(region()$Property_Type)\n    updateSelectInput(inputId = \"type\", choices = choices)\n  })\n  type &lt;- reactive({\n    req(input$type)\n    filter(region(), Property_Type == input$type)\n  })\n  \n  #——————————————————————————————————————————————————————————————————————Statistics\n  #——————————————————————————————————————————————————————————————————————barchart\n  output$barchart &lt;- renderPlot({\n    analysis &lt;- visualdata %&gt;%\n      group_by_(.dots = input$xcol1) %&gt;%\n      summarise(basket_value = mean(`Monthly_Rent_SGD`, na.rm = T))\n    \n    p &lt;- ggplot(analysis, aes_string(y = 'basket_value', x = input$xcol1)) +\n      geom_bar(aes_string(fill = input$xcol1), stat = 'identity') +\n      labs(title = 'Average Rental Price', subtitle = paste('by', input$xcol1), \n           x = input$xcol1, y = 'Rental Price ($)',\n           fill = input$xcol1)\n    return(p)\n  })\n  #——————————————————————————————————————————————————————————————————————Boxplot1\n  output$Boxplot1 &lt;- renderPlot({\n    p1 &lt;- ggplot(visualdata, aes(x=`Planning_Region`, y= `Monthly_Rent_SGD`, fill=`Property_Type`)) +\n      geom_boxplot() +\n      facet_wrap(~`Planning_Region`, scales = \"free\") +\n      labs(x=\"Planning Region\", y=\"Monthly Rent\")\n    return(p1)\n  })\n  #——————————————————————————————————————————————————————————————————————Boxplot2\n  output$Boxplot2 &lt;- renderPlot({\n    p2 &lt;- ggplot(visualdata, aes(x=`Planning_Region`, y= `Monthly_Rent_SGD`)) +\n      geom_boxplot() +\n      facet_wrap(~`Property_Type`, scales = \"free\") +\n      labs(x=\"Planning Region\", y=\"Monthly Rent\") +\n      theme(axis.text.x = element_text(angle = 90))\n    return(p2)\n  })\n  #——————————————————————————————————————————————————————————————————————Boxplot3\n  output$Boxplot3 &lt;- renderPlot({\n    p3 &lt;- ggplot(visualdata, aes(x=`Property_Type`, y= `Monthly_Rent_SGD`)) +\n      geom_boxplot() +\n      facet_wrap(~`Planning_Region`, scales = \"free\") +\n      labs(x=\"Property Type\", y=\"Monthly Rent\") +\n      theme(axis.text.x = element_text(angle = 90))\n    return(p3)\n  })\n  #——————————————————————————————————————————————————————————————————————Scatterplot1\n  output$Scatterplot1 &lt;- renderPlot({\n    p4 &lt;- ggplot(visualdata, aes(x=`distance_to_school`, y=`Monthly_Rent_SGD`)) +\n      geom_point(size=0.5) +\n      scale_x_continuous(breaks = seq(0, 2, by = 0.2)) +\n      coord_cartesian(xlim = c(0, 2)) +\n      facet_grid(`Planning_Region` ~ `Property_Type`, scales = \"free\", space =\"fixed\") +\n      labs(x='Distance to School', y = 'Monthly Rent') +\n      theme(axis.text.x = element_text(angle = 90))\n    return(p4)\n  })\n  #——————————————————————————————————————————————————————————————————————Scatterplot2\n  output$Scatterplot2 &lt;- renderPlot({\n    p5 &lt;- ggplot(visualdata, aes(x=`distance_to_mrt`, y=`Monthly_Rent_SGD`)) +\n      geom_point(size=0.5) +\n      scale_x_continuous(breaks = seq(0, 2, by = 0.2)) +\n      coord_cartesian(xlim = c(0, 2)) +\n      facet_grid(`Planning_Region` ~ `Property_Type`, scales = \"free\", space =\"fixed\") +\n      labs(x='Distance to MRT', y = 'Monthly Rent') +\n      theme(axis.text.x = element_text(angle = 90))\n    return(p5)\n  })\n  #——————————————————————————————————————————————————————————————————————Scatterplot3\n  output$Scatterplot3 &lt;- renderPlot({\n    p6 &lt;- ggplot(visualdata, aes(x=`Floor_Area_SQFT_Avg`, y=`Monthly_Rent_SGD`)) +\n      geom_point(size=0.5) +\n      #  scale_x_continuous(breaks = seq(0, 2, by = 0.2)) +\n      #  coord_cartesian(xlim = c(0, 2)) +\n      facet_grid(`Planning_Region` ~ `Property_Type`, scales = \"free\", space =\"fixed\") +\n      labs(x='Floor Area SQFT', y = 'Monthly Rent') +\n      theme(axis.text.x = element_text(angle = 90))\n    return(p6)\n  })  \n  #——————————————————————————————————————————————————————————————————————matrix\n  output$matrix &lt;- renderPlot({\n    pm &lt;- pairs(~visualdata$Monthly_Rent_SGD + visualdata$Floor_Area_SQM_Avg + visualdata$Floor_Area_SQFT_Avg + visualdata$distance_to_mrt, data = visualdata,\n                main = \"Scatterplot Matrix\")\n    return(pm)\n  })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Peer critique and DataVis Makeover",
    "section": "",
    "text": "This critique will evaluate a peer’s take-home exercise, specifically Take-home Exercise 1, focusing on clarity and aesthetics.\n\nThe original design will then be remade using data visualization design principles and best practices using ggplot2, its extensions, and tidyverse packages.\n\npacman::p_load(ggrepel, ggthemes, hrbrthemes, patchwork, tidyverse, haven, gridExtra, ggplot2, plotly, ggridges, cowplot)\n\n\nThe original dataset (Student questionnaire data file) was downloaded from PISA.\n\n\nData Loading and Filtering\nData Preparation\n\n\n\n\nstu_qqq &lt;- read_sas(\"../../data/cy08msp_stu_qqq.sas7bdat\")\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\nwrite_rds(stu_qqq_SG,\n          \"data/stu_qqq_SG.rds\")\nRelated_math_read_scie_data &lt;- stu_qqq_SG %&gt;%\n  select(contains(c(\"ID\",\"ST004D01T\",\"math\", \"read\", \"scie\",\"ST259Q01JA\",\"ST259Q02JA\",\"ST005Q01JA\",\"ST007Q01JA\")))\nwrite_rds(Related_math_read_scie_data,\n          \"data/Related_math_read_scie_data.rds\")\n\n\n\n\nRelated_math_read_scie_data &lt;- \nread_rds(\"data/Related_math_read_scie_data.rds\")\n\n# Data about Maths/Read/Science\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(avg_pvMATH = rowMeans(select(., ends_with(\"Math\")), na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(avg_pvREAD = rowMeans(select(., ends_with(\"READ\")), na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(avg_pvSCIE = rowMeans(select(., ends_with(\"SCIE\")), na.rm = TRUE))\n\n# Data about School\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  mutate(avg_pvMATH_school = mean(avg_pvMATH, na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  mutate(avg_pvREAD_school = mean(avg_pvREAD, na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  mutate(avg_pvSCIE_school = mean(avg_pvSCIE, na.rm = TRUE))\n\n# Data about Socioeconomic Status\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(Parent_Edu_level = ST005Q01JA + ST007Q01JA)\n\ndf &lt;- Related_math_read_scie_data"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "title": "Take-home Exercise 2: Peer critique and DataVis Makeover",
    "section": "",
    "text": "This critique will evaluate a peer’s take-home exercise, specifically Take-home Exercise 1, focusing on clarity and aesthetics.\n\nThe original design will then be remade using data visualization design principles and best practices using ggplot2, its extensions, and tidyverse packages.\n\npacman::p_load(ggrepel, ggthemes, hrbrthemes, patchwork, tidyverse, haven, gridExtra, ggplot2, plotly, ggridges, cowplot)\n\n\nThe original dataset (Student questionnaire data file) was downloaded from PISA.\n\n\nData Loading and Filtering\nData Preparation\n\n\n\n\nstu_qqq &lt;- read_sas(\"../../data/cy08msp_stu_qqq.sas7bdat\")\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\nwrite_rds(stu_qqq_SG,\n          \"data/stu_qqq_SG.rds\")\nRelated_math_read_scie_data &lt;- stu_qqq_SG %&gt;%\n  select(contains(c(\"ID\",\"ST004D01T\",\"math\", \"read\", \"scie\",\"ST259Q01JA\",\"ST259Q02JA\",\"ST005Q01JA\",\"ST007Q01JA\")))\nwrite_rds(Related_math_read_scie_data,\n          \"data/Related_math_read_scie_data.rds\")\n\n\n\n\nRelated_math_read_scie_data &lt;- \nread_rds(\"data/Related_math_read_scie_data.rds\")\n\n# Data about Maths/Read/Science\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(avg_pvMATH = rowMeans(select(., ends_with(\"Math\")), na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(avg_pvREAD = rowMeans(select(., ends_with(\"READ\")), na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(avg_pvSCIE = rowMeans(select(., ends_with(\"SCIE\")), na.rm = TRUE))\n\n# Data about School\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  mutate(avg_pvMATH_school = mean(avg_pvMATH, na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  mutate(avg_pvREAD_school = mean(avg_pvREAD, na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  mutate(avg_pvSCIE_school = mean(avg_pvSCIE, na.rm = TRUE))\n\n# Data about Socioeconomic Status\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(Parent_Edu_level = ST005Q01JA + ST007Q01JA)\n\ndf &lt;- Related_math_read_scie_data"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-critique-and-remake",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-critique-and-remake",
    "title": "Take-home Exercise 2: Peer critique and DataVis Makeover",
    "section": "\n2 Visualization Critique and Remake",
    "text": "2 Visualization Critique and Remake\n\n2.1 Maths/Reading/Science Distributions\n\n2.1.1 Critique\nThree histograms are used to reveal the distribution of students’ maths, reading, and science score.\n\nClick to view the code.p1 &lt;- ggplot(data=Related_math_read_scie_data, aes(x = avg_pvMATH)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  geom_vline(aes(xintercept = median(avg_pvMATH)), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = median(Related_math_read_scie_data$avg_pvMATH), y = 30, \n           label = paste(\"Median:\", round(median(Related_math_read_scie_data$avg_pvMATH), 2)), \n           vjust = 1, color = \"red\") +\n  labs(y = \"Count\")\n\np2 &lt;- ggplot(data=Related_math_read_scie_data, aes(x = avg_pvREAD)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  geom_vline(aes(xintercept = median(avg_pvREAD)), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = median(Related_math_read_scie_data$avg_pvREAD), y = 30, \n           label = paste(\"Median:\", round(median(Related_math_read_scie_data$avg_pvREAD), 2)), \n           vjust = 1, color = \"red\") +\n  labs(y = \"Count\")\n\np3 &lt;- ggplot(data=Related_math_read_scie_data, aes(x = avg_pvSCIE)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  geom_vline(aes(xintercept = median(avg_pvSCIE)), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = median(Related_math_read_scie_data$avg_pvSCIE), y = 30, \n           label = paste(\"Median:\", round(median(Related_math_read_scie_data$avg_pvSCIE), 2)), \n           vjust = 1, color = \"red\") +\n  labs(y = \"Count\")\n\np1 + p2 + p3 +\n  plot_layout(guides = \"collect\") +\n  plot_annotation(title = \"Distributions of Maths/Reading/Science with Median Lines\", tag_levels = \"I\")\n\n\n\n\n\n\n\nClarity\n\nThe title and tag levels are clear and informative, providing a quick overview.\nMedian lines and annotations effectively emphasize the central tendency of each distribution, but the current positioning is relatively low, and in some cases, line overlap might hinder clarity.\nThe color contrast between elements enhances clarity.\nThe lack of consistent y-axis scaling across plots makes horizontal comparisons challenging.\n\nAesthetics\n\nThe color palette is visually appealing, with effective use of grey, black, and red.\nThe plot layout, combining three plots in a row, facilitates visual comparison.\nWell-balanced annotation placement avoids clutter and maintains readability.\n\n2.1.2 Remake\n\nClick to view the code.p1 &lt;- ggplot(data=Related_math_read_scie_data, aes(x = avg_pvMATH)) +\n  geom_histogram(bins=10, boundary = 100, color=\"black\", fill=\"skyblue\") +\n  geom_vline(aes(xintercept = median(avg_pvMATH)), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = median(Related_math_read_scie_data$avg_pvMATH), y = Inf, \n           label = paste(\"Median:\", round(median(Related_math_read_scie_data$avg_pvMATH), 2)), \n           vjust = 1, color = \"red\") +\n  labs(y = \"Count\", x=\"Average Maths Score\", subtitle = \"Maths\") +\n  coord_cartesian(ylim = c(0,2000))\n\np2 &lt;- ggplot(data=Related_math_read_scie_data, aes(x = avg_pvREAD)) +\n  geom_histogram(bins=10, boundary = 100, color=\"black\", fill=\"skyblue\") +\n  geom_vline(aes(xintercept = median(avg_pvREAD)), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = median(Related_math_read_scie_data$avg_pvREAD), y = Inf, \n           label = paste(\"Median:\", round(median(Related_math_read_scie_data$avg_pvREAD), 2)), \n           vjust = 1, color = \"red\") +\n  labs(y = \"Count\", x=\"Average Reading Score\", subtitle = \"Reading\") +\n  coord_cartesian(ylim = c(0,2000))\n\np3 &lt;- ggplot(data=Related_math_read_scie_data, aes(x = avg_pvSCIE)) +\n  geom_histogram(bins=10, boundary = 100, color=\"black\", fill=\"skyblue\") +\n  geom_vline(aes(xintercept = median(avg_pvSCIE)), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = median(Related_math_read_scie_data$avg_pvSCIE), y = Inf, \n           label = paste(\"Median:\", round(median(Related_math_read_scie_data$avg_pvSCIE), 2)), \n           vjust = 1, color = \"red\") +\n  labs(y = \"Count\", x=\"Average Science Score\", subtitle = \"Science\") +\n  coord_cartesian(ylim = c(0,2000))\n\np1 + p2 + p3 +\n  plot_annotation(title = \"Distributions of Maths/Reading/Science with Median Lines\")\n\n\n\n\n\n\n\nClarity\n\nThe modification ensures a consistent y-axis range across all three plots. This improvement makes it easier to compare the distributions vertically, enhancing clarity.\nThe addition of subtitles (“Maths,” “Reading,” “Science”) provides clear identification for each plot, aiding interpretation.\n\nAesthetics\n\nAdjusting the positioning of annotations prevents overlap issues and ensures better visibility of median information.\nThe modification includes changing the color of the histogram bars to skyblue creating a distinct visual contrast with the grey background. This adjustment enhances visibility and makes the distribution of scores more apparent to the viewer.\n\n2.2 The Relationship between Gender and Performances\n\n2.2.1 Critique\nThree histograms are used to show the relationship between student’ gender and performances.\n\nClick to view the code.p4 &lt;- ggplot(data = Related_math_read_scie_data, aes(x = avg_pvMATH, fill = factor(ST004D01T))) +\n  geom_histogram(bins = 10, color = \"grey30\", position = \"identity\", alpha = 0.7) +\n  labs(x = \"avg_pvMATH\", y = \"Count\", fill = \"Gender\") +\n  scale_fill_manual(values = c(\"skyblue\", \"pink\"))\n\np5 &lt;- ggplot(data = Related_math_read_scie_data, aes(x = avg_pvREAD, fill = factor(ST004D01T))) +\n  geom_histogram(bins = 10, color = \"grey30\", position = \"identity\", alpha = 0.7) +\n  labs(x = \"avg_pvREAD\", y = \"Count\", fill = \"Gender\") +\n  scale_fill_manual(values = c(\"skyblue\", \"pink\"))\n\np6 &lt;- ggplot(data = Related_math_read_scie_data, aes(x = avg_pvSCIE, fill = factor(ST004D01T))) +\n  geom_histogram(bins = 10, color = \"grey30\", position = \"identity\", alpha = 0.7) +\n  labs(x = \"avg_pvSCIE\", y = \"Count\", fill = \"Gender\") +\n  scale_fill_manual(values = c(\"skyblue\", \"pink\"))\n\np4 + p5 + p6 +\n  plot_layout(guides = \"collect\") +\n  plot_annotation(title = \"The Relationship between Gender and Performances\", tag_levels = \"I\")\n\n\n\n\n\n\n\nClarity\n\nColoring the histograms based on the ‘Gender’ column effectively communicates the gender distribution. However, in this context, where ‘1’ represents girls and ‘2’ represents boys, the color assignment may be counterintuitive. For instance, the use of pink for boys and blue for girls might lead to potential misinterpretations.\nAdding a layer of transparency ensures that overlapping bars are easily distinguishable and enhances the clarity of the data presentation.\n\nAesthetics\n\nThe selection of a subdued grey color for histogram outlines maintains a clean and professional appearance. This choice enhances the visual appeal of the plots without distracting from the filled bars, contributing to a balanced aesthetic presentation.\nthe chosen color palette is aesthetically pleasing.\n\n2.2.2 Remake\n\nClick to view the code.p4 &lt;- ggplot(data = Related_math_read_scie_data, aes(x = avg_pvMATH, fill = factor(ST004D01T))) +\n  geom_density(alpha = 0.7, color = \"black\") +\n  labs(x = \"Average Maths Score\", y = \"Density\", fill = \"Gender\", subtitle = \"Maths\") +\n  scale_fill_manual(values = c(\"pink\", \"skyblue\")) +\n  coord_cartesian(xlim = c(150,830))\n\np5 &lt;- ggplot(data = Related_math_read_scie_data, aes(x = avg_pvREAD, fill = factor(ST004D01T))) +\n  geom_density(alpha = 0.7, color = \"black\") +\n  labs(x = \"Average Reading Score\", y = \"Density\", fill = \"Gender\", subtitle = \"Reading\") +\n  scale_fill_manual(values = c(\"pink\", \"skyblue\")) +\n  coord_cartesian(xlim = c(150,830))\n\np6 &lt;- ggplot(data = Related_math_read_scie_data, aes(x = avg_pvSCIE, fill = factor(ST004D01T))) +\n  geom_density(alpha = 0.7, color = \"black\") +\n  labs(x = \"Average Science Score\", y = \"Density\", fill = \"Gender\", subtitle = \"Science\") +\n  scale_fill_manual(values = c(\"pink\", \"skyblue\")) +\n  coord_cartesian(xlim = c(150,830))\n\nplot_grid(p4, p5, p6, ncol = 1, align = \"v\") +\n  plot_annotation(title = \"The Relationship between Gender and Performances\")\n\n\n\n\n\n\n\nClarity\n\nTransitioning from histograms to density plots provides a more intuitive representation of the smooth distribution of data, reducing potential interference from fluctuations in bar charts.\nAdding subtitles for each plot improves interpretability, providing specific context and contributing to a clearer understanding of the analysis.\n\nAesthetics\n\nAdjusting the color scheme to feature pink for girls (1) and sky blue for boys (2) enhances visual contrast, improving overall aesthetics and aiding in gender differentiation.\nAdopting a vertical layout and unifying the x-axis simplifies comparisons, resulting in a more cohesive and accessible exploration of the gender-performance relationship.\n\n2.3 The Relationship between School and Performances\n\n2.3.1 Critique\nThree scatter plots are used to depict the relationship between school and the average performance in Mathematics, Reading, and Science, respectively.\n\nClick to view the code.p7 &lt;- ggplot(data = Related_math_read_scie_data, \n             aes(x = CNTSCHID, \n                 y = avg_pvMATH_school)) +\n  geom_point() +\n  geom_smooth(formula = y~x, method = lm, \n              size = 0.5) +  \n  labs(x = \"School ID\", y = \"Average PV Maths\")\n\np8 &lt;- ggplot(data = Related_math_read_scie_data, \n             aes(x = CNTSCHID, \n                 y = avg_pvREAD_school)) +\n  geom_point() +\n  geom_smooth(formula = y~x, method = lm, \n              size = 0.5) +\n  labs(x = \"School ID\", y = \"Average PV Read\")\n\np9 &lt;- ggplot(data = Related_math_read_scie_data, \n             aes(x = CNTSCHID, \n                 y = avg_pvSCIE_school)) +\n  geom_point() +\n  geom_smooth(formula = y~x, method = lm, \n              size = 0.5) +  \n  labs(x = \"School ID\", y = \"Average PV Scie\")\n\np7 + p8 + p9 +\n    plot_layout(guides = \"collect\") +\n  plot_annotation(title = \"The Relationship between School and Performances\", tag_levels = \"I\")\n\n\n\n\n\n\n\nClarity\n\nThe scatter plots and accompanying regression lines effectively depict the relationship between school ID (CNTSCHID) and average performance scores.\nThe overlapping school IDs on the x-axis create difficulty in distinguishing individual data points, potentially hindering the clarity of the visual representation.\n\nAesthetics\n\nThe title provides a clear context for the visualizations.\nConsider exploring alternative visualizations, to present the relationship between school ID and performance without solely relying on regression lines. Given that school ID and performance may not exhibit a clear linear relationship, using different visualization techniques could offer a more nuanced and informative representation.\n\n2.3.2 Remake\n\nClick to view the code.# School Average Scores Recalculating\nSchool_Avg_Scores &lt;- Related_math_read_scie_data %&gt;%\n  group_by(CNTSCHID) %&gt;%\n  summarize(\n    Avg_Math_Score = mean(avg_pvMATH, na.rm = TRUE),\n    Avg_Reading_Score = mean(avg_pvREAD, na.rm = TRUE),\n    Avg_Science_Score = mean(avg_pvSCIE, na.rm = TRUE)\n  )\nSchool_Avg_Scores_subjects &lt;- School_Avg_Scores %&gt;%\n  select(CNTSCHID, starts_with(\"Avg_Math\"), starts_with(\"Avg_Reading\"), starts_with(\"Avg_Science\"))\n\nSchool_Avg_Scores_long &lt;- School_Avg_Scores_subjects %&gt;%\n  pivot_longer(cols = -CNTSCHID, names_to = \"Subject\", values_to = \"Score\")\n\noutliers_data &lt;- School_Avg_Scores %&gt;%\n  pivot_longer(cols = starts_with(\"Avg_\"), names_to = \"Subject\", values_to = \"Score\") %&gt;%\n  group_by(Subject) %&gt;%\n  arrange(Score) %&gt;%\n  slice(c(1:2, (n() - 2):(n())))\n\n# Boxplot Visualisation\nggplot(School_Avg_Scores_long, aes(x = Subject, y = Score, fill = Subject)) +\n  geom_boxplot(fill = \"skyblue\") +\n  geom_text_repel(data = outliers_data, aes(label = CNTSCHID), position = position_dodge(width = 1), box.padding = 0.8, force = 1, segment.color = \"grey50\", size = 1) + \n  labs(title = \"The Relationship between School and Performances\", x = \"\", y = \"Score\") +\n  theme_minimal() +\n  theme(text = element_text(size = 10),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nClarity\n\nThe application of boxplot for visualization introduces a shift from previous scatter plots, offering a more effective means of comparing subject-wise performances.\nLabeling the top three and bottom two schools with the highest and lowest scores, respectively, enhances clarity by spotlighting significant outliers.\n\nAesthetics\n\nThe transition from scatter plots to box plots aligns with best practices for clearer representation and interpretation of the data.\nThe general arrangement is logical, and the boxplot is well-structured along the X-axis, creating a clear and organized chart that facilitates readability.\n\n2.4 The Relationship between Socioeconomic Status and Performances\n\n2.4.1 Critique\nA scatter plot with three regression lines is used to illustrate the relationship between socioeconomic status and the average performance scores in Mathematics, Reading, and Science.\n\nClick to view the code.df &lt;- Related_math_read_scie_data\n\nggplot(df, aes(x = Parent_Edu_level)) +\n  geom_point(aes(y = avg_pvMATH, color = \"Math\"), na.rm = TRUE) +\n  geom_smooth(aes(y = avg_pvMATH, color = \"Math\"), method = \"lm\", se = FALSE, na.rm = TRUE) +\n  geom_point(aes(y = avg_pvREAD, color = \"Read\"), na.rm = TRUE) +\n  geom_smooth(aes(y = avg_pvREAD, color = \"Read\"), method = \"lm\", se = FALSE, na.rm = TRUE) +\n  geom_point(aes(y = avg_pvSCIE, color = \"Science\"), na.rm = TRUE) +\n  geom_smooth(aes(y = avg_pvSCIE, color = \"Science\"), method = \"lm\", se = FALSE, na.rm = TRUE) +\n  labs(title = \"Relationship between Performance and Socioeconomic Status\",\n       x = \"Socioeconomic Status (Lower values indicate higher status)\",\n       y = \"Average PV Score\") +\n  scale_color_manual(values = c(\"Math\" = \"blue\", \"Read\" = \"green\", \"Science\" = \"red\")) +\n  theme_minimal()\n\n\n\n\n\n\n\nClarity\n\nThe plot lacks immediate clarity as the viewer may struggle to discern the primary purpose or key relationships at first glance.\nOverlapping points and regression lines in dense areas might reduce clarity.\n\nAesthetics\n\nThe color scheme, featuring blue for math, green for reading, and red for science, is visually appealing and helps differentiate the three aspects of academic performance.\nDue to the discrete nature of socioeconomic status, using points to represent the data may not be the most suitable choice, as it can lead to overlapping and a lack of clarity in distinguishing different levels of socioeconomic status.\n\n2.4.2 Remake\n\nClick to view the code.p10 &lt;- ggplot(data = Related_math_read_scie_data, aes(x = factor(Parent_Edu_level), y = avg_pvMATH)) +\n  geom_boxplot(width = 0.5, fill = \"skyblue\") +\n  stat_summary(fun = \"median\", geom = \"line\", aes(group = 1), color = \"red\", linewidth = 1) +  \n  labs(x = \"Socioeconomic Status\", y = \"Average Maths Score\", subtitle = \"Maths\") +\n  theme_classic()\n\np11 &lt;- ggplot(data = Related_math_read_scie_data, aes(x = factor(Parent_Edu_level), y = avg_pvREAD)) +\n  geom_boxplot(width = 0.5, fill = \"skyblue\") +\n  stat_summary(fun = \"median\", geom = \"line\", aes(group = 1), color = \"red\", linewidth = 1) +  \n  labs(x = \"Socioeconomic Status\", y = \"Average Reading Score\", subtitle = \"Reading\") +\n  theme_classic()\n\np12 &lt;- ggplot(data = Related_math_read_scie_data, aes(x = factor(Parent_Edu_level), y = avg_pvSCIE)) +\n  geom_boxplot(width = 0.5, fill = \"skyblue\") +\n  stat_summary(fun = \"median\", geom = \"line\", aes(group = 1), color = \"red\", linewidth = 1) +  \n  labs(x = \"Socioeconomic Status\", y = \"Average Science Score\", subtitle = \"Science\") +\n  theme_classic()\n\np10 + p11 + p12 +\n  plot_annotation(title = \"The Relationship between Performance and Socioeconomic Status\n                                                                 (Lower values indicate higher status)\")\n\n\n\n\n\n\n\nClarity\n\nThe trio of plots effectively conveys the distribution of average scores across different socioeconomic status levels. The use of boxplots with median lines provides a clear representation of the central tendency and spread within each category.\nThe subtitles “Maths,” “Reading,” and “Science” help viewers quickly identify the subject matter of each plot, enhancing overall clarity.\nGrouping the plots together in a single arrangement allows for easy visual comparison across subjects, contributing to a coherent presentation.\n\nAesthetics\n\nThe choice of the sky-blue color for boxplots is aesthetically pleasing and maintains consistency across all three plots.\nThe red median lines stand out well against the blue background, aiding in the identification of central tendencies.\nThe overall design with classic themes is neat and professional, contributing to a visually appealing representation of the relationship between performance and socioeconomic status."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#learning-points",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#learning-points",
    "title": "Take-home Exercise 2: Peer critique and DataVis Makeover",
    "section": "\n3 Learning Points",
    "text": "3 Learning Points\nTake-home exercise 2 served as a valuable reflection point for me, offering a different perspective on my classmates’ work in comparison to my own take-home exercise 1. This process allowed me to appreciate the diversity in design approaches and draw inspiration from their visualizations.\nOne key takeaway is the realization that there isn’t a singular correct method for designing visualizations. The crucial factors lie in ensuring clarity, aesthetic appeal, and the effective communication of a meaningful message. The act of revisiting my initial work alongside classmates’ contributions has been enlightening, providing me with fresh ideas for refining my take-home exercise 1.\nExamining my peers’ visualizations has not only expanded my understanding but has also enhanced my drawing skills. Witnessing different approaches has sparked new ideas and creativity within the realm of data visualization. This experience reinforced the notion that reassessing a problem, comprehending its origins, and amalgamating diverse perspectives can lead to an improved version of one’s work.\nIn essence, this process has been immensely beneficial, offering a deeper comprehension and hands-on practice in the art and science of data visualization."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KAI",
    "section": "",
    "text": "Welcome to Visual Analytics & Application Learning Journey webpage.\nIn this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class Exercise 7: Visualising and Analysing Geographic Data",
    "section": "",
    "text": "View the slides to learn more about:"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#isomap",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#isomap",
    "title": "In-class Exercise 7: Visualising and Analysing Geographic Data",
    "section": "\n1 IsoMap",
    "text": "1 IsoMap\n\n1.1 Loading R Package\n\npacman::p_load(sf, terra, gstat, tmap, viridis, tidyverse)\n\n\n1.2 Dataset\n\nrfstations &lt;- read.csv(\"data/aspatial/RainfallStation.csv\")\n\n\nrfdata &lt;- read_csv(\"data/aspatial/DAILYDATA_202402.csv\") %&gt;%\n  select(c(1, 5)) %&gt;%\n  group_by(Station) %&gt;%\n  summarise(MONTHSUM = sum(`Daily Rainfall Total (mm)`)) %&gt;%\n  ungroup()\n\n\nrfdata &lt;- rfdata %&gt;%\n  left_join(rfstations)\n\n\nrfdata_sf &lt;- st_as_sf(rfdata,\n                      coords = c(\"Longitude\", \"Latitude\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\nmpsz2019 &lt;- st_read(dsn = \"data/geospatial\", layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `E:\\kaixx1027\\ISSS608-VAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n1.3 Visualisation\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\ntm_shape(mpsz2019)+\n  tm_borders()+\n  tm_shape(rfdata_sf)+\n  tm_dots(col= 'MONTHSUM')\n\n\n\n\ntmap_mode(\"plot\")\n\n\ngrid &lt;- terra::rast(mpsz2019,\n                    nrows = 690,\n                    ncols = 1075)\n\nxy &lt;-terra::xyFromCell(grid,\n                       1:ncell(grid))\n\n\ncoop &lt;-st_as_sf(as.data.frame(xy),\n                coords = c(\"x\",\"y\"),\n                crs = st_crs(mpsz2019))\ncoop &lt;-st_filter(coop,mpsz2019)\n\n\nres &lt;- gstat(formula = MONTHSUM ~ 1,\n             locations = rfdata_sf,\n             nmax = 15,\n             set = list(idp = 0))\n\nresp&lt;- predict(res,coop)\n\n[inverse distance weighted interpolation]\n\nresp$x&lt;-st_coordinates(resp)[,1]\nresp$y&lt;-st_coordinates(resp)[,2]\nresp$pred &lt;-resp$var1.pred\n\npred&lt;- terra::rasterize(resp,grid,\n                        field=\"pred\",\n                        fun=\"mean\")\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(pred)+\n  tm_raster(alpha = 0.6,\n            palette = \"viridis\")\n\n\n\n\n\n\n\n\nv&lt;- variogram(log(MONTHSUM)~1,\n              data = rfdata_sf)\nplot(v)\n\n\n\n\n\n\n\n\nfv&lt;-fit.variogram(object = v,\n                  model = vgm(psill = 0.5,model = \"Sph\",\n                              range = 900,nugget = 0.1))\nfv\n\n\n  \n\n\nplot(v,fv,cex =1.5)\n\n\n\n\n\n\n\n\nk&lt;-gstat(formula = log(MONTHSUM)~1,\n              data = rfdata_sf,\n         model=fv)\n\n\nresp&lt;- predict(k,coop)\n\n[using ordinary kriging]\n\nresp$x&lt;-st_coordinates(resp)[,1]\nresp$y&lt;-st_coordinates(resp)[,2]\nresp$pred &lt;-resp$var1.pred\n\nkpred&lt;- terra::rasterize(resp,grid,\n                        field=\"pred\")\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(kpred)+\n  tm_raster(alpha = 0.6,\n            palette = \"viridis\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6: Visualising and Analysing Time-Oriented Data",
    "section": "",
    "text": "View the slides to learn more about:"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#tableau",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#tableau",
    "title": "In-class Exercise 6: Visualising and Analysing Time-Oriented Data",
    "section": "\n1 Tableau",
    "text": "1 Tableau\nVisitor arrival by country\nClick here to view more."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#hirizon-plot",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#hirizon-plot",
    "title": "In-class Exercise 6: Visualising and Analysing Time-Oriented Data",
    "section": "\n2 Hirizon Plot",
    "text": "2 Hirizon Plot\n\n2.1 Loading R Package\n\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\n2.2 Dataset\n\naverp &lt;- read_csv(\"../../data/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))\n\n\nClick here to view the code.averp %&gt;% \n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4: Fundamentals of Visual Analytics",
    "section": "",
    "text": "View the slides to learn more about:\n\nVisual Analytics for Knowledge Discovery\nVisual Analytics Approach for Statistical Testing\nVisual Analytics for Building Better Models\nVisualising Uncertainty\nVariation and Its Discontents"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2: Designing Graphs to Enlighten",
    "section": "",
    "text": "In this session, we dived into the fundamentals of designing impactful graphs and took our first steps into the world of Tableau.\nCheck out our learnings here."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "",
    "text": "pacman::p_load(lubridate, ggthemes, reactable, reactablefmtr, gt, gtExtras, tidyverse, RODBC, svglite) \n\n\nFor the purpose of this study, a personal database in Microsoft Access mdb format called Coffee Chain will be used.\nIn the code chunk below, odbcConnectAccess() of RODBC package is used used to import a database query table into R.\n\nlibrary(RODBC)\ncon &lt;- odbcConnectAccess2007('../../data/Coffee Chain.mdb')\ncoffeechain &lt;- sqlFetch(con, 'CoffeeChain Query')\nwrite_rds(coffeechain, \"../../data/CoffeeChain.rds\")\nodbcClose(con)\n\nNote: Before running the code chunk, you need to change the R system to 32bit version. This is because the odbcConnectAccess() is based on 32bit and not 64bit\n\nThe code chunk below is used to import CoffeeChain.rds into R.\n\ncoffeechain &lt;- read_rds(\"../../data/rds/CoffeeChain.rds\")\n\nNote: This step is optional if coffeechain is already available in R.\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nClick to view the code.product &lt;- coffeechain %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %&gt;%\n  ungroup()\n\n\n\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nClick to view the code.ggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#getting-started",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "",
    "text": "pacman::p_load(lubridate, ggthemes, reactable, reactablefmtr, gt, gtExtras, tidyverse, RODBC, svglite) \n\n\nFor the purpose of this study, a personal database in Microsoft Access mdb format called Coffee Chain will be used.\nIn the code chunk below, odbcConnectAccess() of RODBC package is used used to import a database query table into R.\n\nlibrary(RODBC)\ncon &lt;- odbcConnectAccess2007('../../data/Coffee Chain.mdb')\ncoffeechain &lt;- sqlFetch(con, 'CoffeeChain Query')\nwrite_rds(coffeechain, \"../../data/CoffeeChain.rds\")\nodbcClose(con)\n\nNote: Before running the code chunk, you need to change the R system to 32bit version. This is because the odbcConnectAccess() is based on 32bit and not 64bit\n\nThe code chunk below is used to import CoffeeChain.rds into R.\n\ncoffeechain &lt;- read_rds(\"../../data/rds/CoffeeChain.rds\")\n\nNote: This step is optional if coffeechain is already available in R.\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\nClick to view the code.product &lt;- coffeechain %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %&gt;%\n  ungroup()\n\n\n\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\nClick to view the code.ggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#plotting-sparklines-using-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#plotting-sparklines-using-ggplot2",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "\n2 Plotting sparklines using ggplot2",
    "text": "2 Plotting sparklines using ggplot2\nIn this section, you will learn how to plot sparklines by using ggplot2.\n\n2.1 Preparing the data\n\nClick to view the code.sales_report &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  group_by(Month, Product) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup() %&gt;%\n  select(Month, Product, Sales)\n\n\nThe code chunk below is used to compute the minimum, maximum and end othe the month sales.\n\nClick to view the code.mins &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.min(Sales))\nmaxs &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.max(Sales))\nends &lt;- group_by(sales_report, Product) %&gt;% \n  filter(Month == max(Month))\n\n\nThe code chunk below is used to compute the 25 and 75 quantiles.\n\nClick to view the code.quarts &lt;- sales_report %&gt;%\n  group_by(Product) %&gt;%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %&gt;%\n  right_join(sales_report)\n\n\n\n2.2 sparklines in ggplot2\n\nClick to view the code.ggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1.0) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "\n3 Static Information Dashboard Design: gt and gtExtras methods",
    "text": "3 Static Information Dashboard Design: gt and gtExtras methods\nIn this section, you will learn how to create static information dashboard by using gt and gtExtras packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\n\n3.1 Plotting a simple bullet chart\nIn this section, you will learn how to prepare a bullet chart report by using functions of gt and gtExtras packages.\n\nClick to view the code.product %&gt;%\n  gt::gt() %&gt;%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\nProduct\ncurrent\n\n\n\nAmaretto\n\n\n\nCaffe Latte\n\n\n\nCaffe Mocha\n\n\n\nChamomile\n\n\n\nColombian\n\n\n\nDarjeeling\n\n\n\nDecaf Espresso\n\n\n\nDecaf Irish Cream\n\n\n\nEarl Grey\n\n\n\nGreen Tea\n\n\n\nLemon\n\n\n\nMint\n\n\n\nRegular Espresso"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-gtextras-method",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-gtextras-method",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "\n4 sparklines: gtExtras method",
    "text": "4 sparklines: gtExtras method\nBefore we can prepare the sales report by product by using gtExtras functions, code chunk below will be used to prepare the data.\n\nClick to view the code.report &lt;- coffeechain %&gt;%\n  mutate(Year = year(Date)) %&gt;%\n  filter(Year == \"2013\") %&gt;%\n  mutate (Month = month(Date, \n                        label = TRUE, \n                        abbr = TRUE)) %&gt;%\n  group_by(Product, Month) %&gt;%\n  summarise(Sales = sum(Sales)) %&gt;%\n  ungroup()\n\n\nIt is important to note that one of the requirement of gtExtras functions is that almost exclusively they require you to pass data.frame with list columns. In view of this, code chunk below will be used to convert the report data.frame into list columns.\n\nClick to view the code.report %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\n  \n\n\n\n\n4.1 Plotting Coffechain Sales report\n\nClick to view the code.report %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %&gt;%\n   gt() %&gt;%\n   gt_plt_sparkline('Monthly Sales',\n                    same_limit = FALSE)\n\n\n\n\n\n\n\n\n\nProduct\nMonthly Sales\n\n\n\nAmaretto\n1.2K\n\n\nCaffe Latte\n1.5K\n\n\nCaffe Mocha\n3.7K\n\n\nChamomile\n3.3K\n\n\nColombian\n5.5K\n\n\nDarjeeling\n3.0K\n\n\nDecaf Espresso\n3.2K\n\n\nDecaf Irish Cream\n2.7K\n\n\nEarl Grey\n3.0K\n\n\nGreen Tea\n1.5K\n\n\nLemon\n4.4K\n\n\nMint\n1.5K\n\n\nRegular Espresso\n1.1K\n\n\n\n\n\n\n\n4.2 Adding statistics\nFirst, calculate summary statistics by using the code chunk below.\n\nClick to view the code.report %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\n\n\nProduct\nMin\nMax\nAverage\n\n\n\nAmaretto\n1016\n1210\n1,119.00\n\n\nCaffe Latte\n1398\n1653\n1,528.33\n\n\nCaffe Mocha\n3322\n3828\n3,613.92\n\n\nChamomile\n2967\n3395\n3,217.42\n\n\nColombian\n5132\n5961\n5,457.25\n\n\nDarjeeling\n2926\n3281\n3,112.67\n\n\nDecaf Espresso\n3181\n3493\n3,326.83\n\n\nDecaf Irish Cream\n2463\n2901\n2,648.25\n\n\nEarl Grey\n2730\n3005\n2,841.83\n\n\nGreen Tea\n1339\n1476\n1,398.75\n\n\nLemon\n3851\n4418\n4,080.83\n\n\nMint\n1388\n1669\n1,519.17\n\n\nRegular Espresso\n890\n1218\n1,023.42\n\n\n\n\n\n\n\n4.3 Combining the data.frame\nNext, use the code chunk below to add the statistics on the table.\n\nClick to view the code.spark &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\n\nClick to view the code.sales &lt;- report %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\n\n\n\nClick to view the code.sales_data = left_join(sales, spark)\n\n\n\n4.4 Plotting the updated data.table\n\nClick to view the code.sales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales',\n                   same_limit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\n\n\n\nAmaretto\n1016\n1210\n1119.000\n1.2K\n\n\nCaffe Latte\n1398\n1653\n1528.333\n1.5K\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n3.7K\n\n\nChamomile\n2967\n3395\n3217.417\n3.3K\n\n\nColombian\n5132\n5961\n5457.250\n5.5K\n\n\nDarjeeling\n2926\n3281\n3112.667\n3.0K\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n3.2K\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n2.7K\n\n\nEarl Grey\n2730\n3005\n2841.833\n3.0K\n\n\nGreen Tea\n1339\n1476\n1398.750\n1.5K\n\n\nLemon\n3851\n4418\n4080.833\n4.4K\n\n\nMint\n1388\n1669\n1519.167\n1.5K\n\n\nRegular Espresso\n890\n1218\n1023.417\n1.1K\n\n\n\n\n\n\n\n4.5 Combining bullet chart and sparklines\nSimilarly, we can combining the bullet chart and sparklines using the steps below.\n\nClick to view the code.bullet &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %&gt;%\n  ungroup() \n\n\n\nClick to view the code.sales_data = sales_data %&gt;%\n  left_join(bullet)\n\n\n\nClick to view the code.sales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales') %&gt;%\n  gt_plt_bullet(column = Actual, \n                target = Target, \n                width = 28,\n                palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\nActual\n\n\n\nAmaretto\n1016\n1210\n1119.000\n1.2K\n\n\n\nCaffe Latte\n1398\n1653\n1528.333\n1.5K\n\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n3.7K\n\n\n\nChamomile\n2967\n3395\n3217.417\n3.3K\n\n\n\nColombian\n5132\n5961\n5457.250\n5.5K\n\n\n\nDarjeeling\n2926\n3281\n3112.667\n3.0K\n\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n3.2K\n\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n2.7K\n\n\n\nEarl Grey\n2730\n3005\n2841.833\n3.0K\n\n\n\nGreen Tea\n1339\n1476\n1398.750\n1.5K\n\n\n\nLemon\n3851\n4418\n4080.833\n4.4K\n\n\n\nMint\n1388\n1669\n1519.167\n1.5K\n\n\n\nRegular Espresso\n890\n1218\n1023.417\n1.1K"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "title": "Hands-on Exercise 10: Information Dashboard Design: R methods",
    "section": "\n5 Interactive Information Dashboard Design: reactable and reactablefmtr methods",
    "text": "5 Interactive Information Dashboard Design: reactable and reactablefmtr methods\nIn this section, you will learn how to create interactive information dashboard by using reactable and reactablefmtr packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\nIn order to build an interactive sparklines, we need to install dataui R package by using the code chunk below.\n\nremotes::install_github(\"timelyportfolio/dataui\")\n\nNext, you all need to load the package onto R environment by using the code chunk below.\n\nlibrary(dataui)\n\n\n5.1 Plotting interactive sparklines\nSimilar to gtExtras, to plot an interactive sparklines by using reactablefmtr package we need to prepare the list field by using the code chunk below.\n\nClick to view the code.report &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize(`Monthly Sales` = list(Sales))\n\n\nNext, react_sparkline will be to plot the sparklines as shown below.\n\nClick to view the code.reactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n5.2 Changing the pagesize\nBy default the pagesize is 10. In the code chunk below, arguments defaultPageSize is used to change the default setting.\n\nClick to view the code.reactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n5.3 Adding points and labels\nIn the code chunk below highlight_points argument is used to show the minimum and maximum values points and label argument is used to label first and last values.\n\nClick to view the code.reactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)\n\n\n\n\n\n\n5.4 Adding reference line\nIn the code chunk below statline argument is used to show the mean line.\n\nClick to view the code.reactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n5.5 Adding bandline\nInstead adding reference line, bandline can be added by using the bandline argument.\n\nClick to view the code.reactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n5.6 Changing from sparkline to sparkbar\nInstead of displaying the values as sparklines, we can display them as sparkbars as shiwn below.\n\nClick to view the code.reactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, clock, tidyverse, graphlayouts)\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\nGAStech_nodes &lt;- read_csv(\"../../data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"../../data/GAStech_email_edge-v2.csv\")\n\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date” data type.\n\nThe code chunk below will be used to perform the changes.\n\nClick to view the code.GAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nThings to learn from the code chunk above\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times. dmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nClick to view the code.glimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; 星期五, 星期五, 星期五, 星期五, 星期五, 星期五, 星期五, 星…\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nClick to view the code.GAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\nThings to learn from the code chunk above\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; 星期日, 星期一, 星期二, 星期三, 星期五, 星期日, 星期一, 星期二…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, clock, tidyverse, graphlayouts)\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\nGAStech_nodes &lt;- read_csv(\"../../data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"../../data/GAStech_email_edge-v2.csv\")\n\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date” data type.\n\nThe code chunk below will be used to perform the changes.\n\nClick to view the code.GAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nThings to learn from the code chunk above\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times. dmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nClick to view the code.glimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; 星期五, 星期五, 星期五, 星期五, 星期五, 星期五, 星期五, 星…\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nClick to view the code.GAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\nThings to learn from the code chunk above\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; 星期日, 星期一, 星期二, 星期三, 星期五, 星期日, 星期一, 星期二…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data with R",
    "section": "\n2 Creating network objects using tidygraph",
    "text": "2 Creating network objects using tidygraph\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n2.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\n\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n2.2 The dplyr verbs in tidygraph\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n# &lt;- iris_tree %&gt;%\n#  activate(nodes) %&gt;%\n#  mutate(Species = ifelse(leaf, as.character(iris$Species)[label], NA)) %&gt;%\n#  activate(edges) %&gt;%\n#  mutate(to_setose = .N()$Species[to] == 'setosa')\n#iris_tree\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n2.3 Using tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nClick to view the code.GAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n2.4 Reviewing the output tidygraph’s graph object\n\nClick to view the code.GAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 星期日       5\n2     1     2 星期一       2\n3     1     2 星期二       3\n# ℹ 1,369 more rows\n\n\n\n2.5 Reviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n2.6 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nClick to view the code.GAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n 1    40    41 星期六      13\n 2    41    43 星期一      11\n 3    35    31 星期二      10\n 4    40    41 星期一      10\n 5    40    43 星期一      10\n 6    36    32 星期日       9\n 7    40    43 星期六       9\n 8    41    40 星期一       9\n 9    19    15 星期三       8\n10    35    38 星期二       8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data with R",
    "section": "\n3 Plotting Static Network Graphs with ggraph package",
    "text": "3 Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n3.1 Plotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nClick to view the code.ggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n3.2 Changing the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\nClick to view the code.g &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n3.3 Changing the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\nClick to view the code.g &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n3.4 Working with ggraph’s layouts\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl.\n\n3.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\nClick to view the code.g &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\n\nlayout argument is used to define the layout to be used.\n\n3.6 Modifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\nClick to view the code.g &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n3.7 Modifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\nClick to view the code.g &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-facet-graphs",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data with R",
    "section": "\n4 Creating facet graphs",
    "text": "4 Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n4.1 Working with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nClick to view the code.set_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n4.2 Working with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\nClick to view the code.set_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n4.3 A framed facet graph\nThe code chunk below adds frame to each graph.\n\nClick to view the code.set_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n4.4 Working with facet_nodes()\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nClick to view the code.set_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#network-metrics-analysis",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data with R",
    "section": "\n5 Network Metrics Analysis",
    "text": "5 Network Metrics Analysis\n\n5.1 Computing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\nClick to view the code.g &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n5.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\nClick to view the code.g &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n5.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\nClick to view the code.g &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 8: Modelling, Visualising and Analysing Network Data with R",
    "section": "\n6 Building Interactive Network Graph with visNetwork",
    "text": "6 Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\n\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\n\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\n6.1 Data preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nClick to view the code.GAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n6.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nClick to view the code.visNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n6.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nClick to view the code.visNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n6.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nClick to view the code.GAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\n\nClick to view the code.visNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n6.5 Working with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n\nThe argument arrows is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\nClick to view the code.visNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n6.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nClick to view the code.visNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_2.html",
    "title": "Hands-on Exercise 7.2: Visualising Geospatial Point Data",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse) \n\n\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\nsgpools &lt;- read_csv(\"../../data/aspatial/SGPools_svy21.csv\")\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nClick to view the code.sgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_2.html#getting-started",
    "title": "Hands-on Exercise 7.2: Visualising Geospatial Point Data",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse) \n\n\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\nsgpools &lt;- read_csv(\"../../data/aspatial/SGPools_svy21.csv\")\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nClick to view the code.sgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_2.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_2.html#drawing-proportional-symbol-map",
    "title": "Hands-on Exercise 7.2: Visualising Geospatial Point Data",
    "section": "\n2 Drawing Proportional Symbol Map",
    "text": "2 Drawing Proportional Symbol Map\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\nClick to view the code.tmap_mode(\"view\")\n\n\n\n2.1 It all started with an interactive point symbol map\n\nClick to view the code.tm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n2.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\nClick to view the code.tm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n2.3 Lets give it a different colour**\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\nClick to view the code.tm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n2.4 I have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\nClick to view the code.tm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\nClick to view the code.tmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "pacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse) \n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\nClick to view the code.attacks &lt;- read_csv(\"../../data/eventlog.csv\")\nkable(head(attacks))\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "pacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse) \n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\nClick to view the code.attacks &lt;- read_csv(\"../../data/eventlog.csv\")\nkable(head(attacks))\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "\n2 Plotting Calendar Heatmap",
    "text": "2 Plotting Calendar Heatmap\n\n2.1 Processing data before making heatmap\nIn order to plot heatmap, we need to process for the useful data.\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\nStep 1: Define a function: for deriving weekday and hour from timestamps\n\nClick to view the code.make_hr_wkday &lt;- function(ts, sc, tz) {real_times &lt;- ymd_hms(ts, \n                                                             tz = tz[1], \n                                                             quiet = TRUE)\n                                       dt &lt;- data.table(source_country = sc,\n                                                        wkday = weekdays(real_times),\n                                                        hour = hour(real_times))\n                                       return(dt)\n}\n\n\n\nymd_hms() and hour() are from lubridate package\nweekdays() is a base R function.\n\nStep 2: Apply function to the data and change the data type\n\nClick to view the code.#apply function to derive wkday and hour from timestamp\nprocessed_attacks &lt;- attacks %&gt;%\n  do(make_hr_wkday(.$timestamp, .$source_country, .$tz))\n\n# Change the Chinese weekday name(default came out in my computer) to English weekday name\nchinese_weekdays &lt;- c(\"星期一\", \"星期二\", \"星期三\", \"星期四\", \"星期五\", \"星期六\", \"星期日\")\nenglish_weekdays &lt;- c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")\nenglish_wkday &lt;- english_weekdays[match(processed_attacks$wkday, chinese_weekdays)]\nprocessed_attacks$wkday &lt;- english_wkday\n\n#Change the data type of wkday and hour to \"fac\" (and also with adding \"tz\" to processed_attacks and sorting by tz)\nprocessed_attacks &lt;- bind_cols(tz = attacks$tz, processed_attacks) %&gt;%\n  mutate(wkday = factor(wkday),\n         hour = factor(hour)) %&gt;%\n  arrange(tz)\n\n# rename processed_attacks with attacks\nassign(\"attacks\", processed_attacks)\n\n#Check the data frame\nkable(head(attacks))\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting.\n\n2.2 Making heatmap\nThe below heatmap chart is made by ggplot2 package: geom_tile()\n\nClick to view the code.#Code for making heatmap\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit() #delete columns which has \"NA\"\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", #this is for making heatmap\n            size = 0.1) + \n  theme_tufte(base_family = \"Calibri\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"sky blue\", \n                      high = \"dark blue\") +\n  labs(x = NULL, #\"Hour in Day\"\n       y = NULL, #\"Weekday\"\n       title = \"Attacks by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6)\n        )\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n2.3 Building Multiple Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\nStep 1: Deriving attack by country\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attacks by country, and\nsave the results in a tibble data frame.\n\n\nClick to view the code.attacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\nClick to view the code.top4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nClick to view the code.ggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte() + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "\n3 Plotting Cycle Plot",
    "text": "3 Plotting Cycle Plot\nIn this section, learning how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\nStep 1: Data Import\n\nair &lt;- read_excel(\"../../data/arrivals_by_air.xlsx\")\n\nStep 2: Deriving month and year fields\n\nClick to view the code.air$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\nStep 3: Extracting the target country\n\nClick to view the code.Vietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\nStep 4: Computing year average arrivals by month\n\nClick to view the code.hline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\nStep 5: Plotting the cycle plot\n\nClick to view the code.Vietnam_visitors_plot &lt;- ggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte()\nVietnam_visitors_plot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "\n4 Plotting Slopegraph",
    "text": "4 Plotting Slopegraph\nIn this section you will learn how to plot a slopegraph by using R. Before getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\nStep 1: Data Import\n\nrice &lt;- read_csv(\"../../data/rice.csv\")\n\nStep 2: Plotting the slopegraph\n\nClick to view the code.rice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\nThings to learn from the code chunk\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "pacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\nwh &lt;- read_csv(\"../../data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#getting-started",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "pacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\nwh &lt;- read_csv(\"../../data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "\n2 Plotting Static Parallel Coordinates Plot",
    "text": "2 Plotting Static Parallel Coordinates Plot\n\n2.1 Plotting a simple parallel coordinates\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n2.2 Plotting a parallel coordinates with boxplot\n\nClick to view the code.ggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n2.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nClick to view the code.ggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n2.4 Rotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nClick to view the code.ggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n2.5 Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nClick to view the code.ggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_4.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 5.4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "\n3 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "3 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n3.1 The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nClick to view the code.wh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n3.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\nClick to view the code.parallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\n3.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunk below.\n\nClick to view the code.parallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n3.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nClick to view the code.histoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "",
    "text": "pacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\nwine &lt;- read_csv(\"../../data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#getting-started",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "",
    "text": "pacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\nwine &lt;- read_csv(\"../../data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "\n2 Building Correlation Matrix: pairs() method",
    "text": "2 Building Correlation Matrix: pairs() method\nReading the syntax description of pairs function.\n\n2.1 Building a basic correlation matrix\n\nClick to view the code.pairs(wine[,1:11])\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function.\nColumns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\nClick to view the code.pairs(wine[,2:12])\n\n\n\n\n\n\n\n\n2.2 Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\nClick to view the code.pairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\nSimilarly, the upper half of the correlation matrix can be displayed by the code chunk below.\n\nClick to view the code.pairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n2.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\n\nClick to view the code.panel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "\n3 Visualising Correlation Matrix: ggcormat()",
    "text": "3 Visualising Correlation Matrix: ggcormat()\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\n\n3.1 The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nClick to view the code.ggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\nClick to view the code.ggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#building-multiple-plots",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "\n4 Building multiple plots",
    "text": "4 Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\nClick to view the code.grouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on Exercise 5.2: Visual Correlation Analysis",
    "section": "\n5 Visualising Correlation Matrix using corrplot Package",
    "text": "5 Visualising Correlation Matrix using corrplot Package\nReading An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n5.1 Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nClick to view the code.wine.cor &lt;- cor(wine[, 1:11])\n\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\nClick to view the code.corrplot(wine.cor)\n\n\n\n\n\n\n\n\ncircle: default visual object used to plot the corrgram\ndefault layout of the corrgram: symmetric matrix\n\ndefault colour scheme - diverging blue-red\nblue - represent pair variables with positive correlation coefficients\nred - represent pair variables with negative correlation coefficients\n\n\nthe intensity of the colour (saturation) - represent the strength of the correlation coefficient\ndarker - relatively stronger linear relationship between the paired variables\nlighter - relatively weaker linear relationship\n\n\n5.2 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle.\nAs shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\n\nsquare\nellipse\n\n\n\n\nClick to view the code.corrplot(wine.cor, method = \"square\") \n\n\n\n\n\n\n\n\n\n\nClick to view the code.corrplot(wine.cor, method = \"ellipse\") \n\n\n\n\n\n\n\n\n\n\n\n5.3 Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\nClick to view the code.corrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\nClick to view the code.corrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\n5.4 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\nClick to view the code.corrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n5.5 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.’\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nClick to view the code.wine.sig = cor.mtest(wine.cor, conf.level= .95)\n\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\nClick to view the code.corrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n5.6 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\nClick to view the code.corrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n5.7 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\nClick to view the code.corrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "",
    "text": "pacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"../../data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#getting-started",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "",
    "text": "pacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"../../data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "\n2 FunnelPlotR methods",
    "text": "2 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n2.1 FunnelPlotR methods: The basic plot\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_type argument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\nClick to view the code.funnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n2.2 FunnelPlotR methods: Makeover 1\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\nClick to view the code.funnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n2.3 FunnelPlotR methods: Makeover 2\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\nClick to view the code.funnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4.4: Building Funnel Plot with R",
    "section": "\n3 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "3 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nBuilding funnel plots step-by-step by using ggplot2.\nEnhancing working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n3.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\nClick to view the code.df &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\n\nNext, the fit.mean is computed by using the code chunk below.\n\nClick to view the code.fit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n3.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nClick to view the code.number.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n3.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nClick to view the code.p &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n3.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nClick to view the code.fp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "title": "Hands-on Exercise 4.2: Visual Statistical Analysis",
    "section": "",
    "text": "ggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\nexam &lt;- read_csv(\"../../data/Exam_data.csv\")\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\nClick to view the code.set.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\nClick to view the code.ggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\nClick to view the code.ggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nClick to view the code.ggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nClick to view the code.exam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nClick to view the code.ggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4.2: Visual Statistical Analysis",
    "section": "",
    "text": "ggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\nexam &lt;- read_csv(\"../../data/Exam_data.csv\")\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\nClick to view the code.set.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\nClick to view the code.ggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\nClick to view the code.ggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nClick to view the code.ggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nClick to view the code.exam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nClick to view the code.ggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-models",
    "title": "Hands-on Exercise 4.2: Visual Statistical Analysis",
    "section": "\n2 Visualising Models",
    "text": "2 Visualising Models\nLearning how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n2.1 Installing and loading the required libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n2.2 Importing Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\nClick to view the code.car_resale &lt;- read_xls(\"../../data/ToyotaCorolla.xls\", \n                       \"data\")\n\n\n\n2.3 Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nClick to view the code.model &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n2.4 Model Diagnostic: checking for multicolinearity\nIn the code chunk, check_collinearity() of performance package.\n\nClick to view the code.check_collinearity(model)\n\n\n  \n\n\n\n\nClick to view the code.check_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n2.5 Model Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nClick to view the code.model1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\n\n2.6 Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\nClick to view the code.check_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\n\n2.7 Model Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\nClick to view the code.check_model(model1)\n\n\n\n\n\n\n\n\n2.8 Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nClick to view the code.plot(parameters(model1))\n\n\n\n\n\n\n\n\n2.9 Visualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nClick to view the code.ggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if packages are installed in the computer. If they are, then they will be launched into R.\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder, plotly, gganimate, tidyverse)\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\n\n\nmutate_at()\nacross()\n\n\n\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"../../data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"../../data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#getting-started",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if packages are installed in the computer. If they are, then they will be launched into R.\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder, plotly, gganimate, tidyverse)\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\n\n\nmutate_at()\nacross()\n\n\n\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"../../data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"../../data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "\n2 Animated Data Visualisation: gganimate methods",
    "text": "2 Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n2.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nClick to view the code.ggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n2.2 Building the animated bubble plot\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nClick to view the code.ggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3.2: Programming Animated Statistical Graphics with R",
    "section": "\n3 Animated Data Visualisation: plotly",
    "text": "3 Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n3.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\nThe animated bubble plot above includes a play/pause button and a slider component for controlling the animation\n\nClick to view the code.gg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nClick to view the code.gg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n3.2 Building an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nClick to view the code.bp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse) \n\n\n\nexam_data &lt;- read.csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse) \n\n\n\nexam_data &lt;- read.csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "\n2 Beyond ggplot2 Annotation: ggrepel",
    "text": "2 Beyond ggplot2 Annotation: ggrepel\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(formula = y~x,\n              method = lm, \n              linewidth = 0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n2.1 Working with ggrepel\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(formula = y~x,\n              method = lm, \n              linewidth=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "\n3 Beyond ggplot2 Themes",
    "text": "3 Beyond ggplot2 Themes\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n3.1 Working with ggtheme package\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n3.2 Working with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "\n4 Beyond Single Graph",
    "text": "4 Beyond Single Graph\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\nNext\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\nLastly\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(formula = y~x,\n              method = lm, \n              size = 0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n4.1 Combining two ggplot2 graphs\n\np1 + p2\n\n\n\n\n\n\n\n\n4.2 Combining three ggplot2 graphs\n\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\n4.3 Creating a composite figure with tag\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n4.4 Creating figure with insert\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n\n\n4.5 Creating a composite figure by using patchwork and ggtheme\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\nexam_data &lt;- read_csv(\"../../data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"../../data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if packages are installed in the computer. If they are, then they will be launched into R.\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse) \n\n\n\nexam_data &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#getting-started",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if packages are installed in the computer. If they are, then they will be launched into R.\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse) \n\n\n\nexam_data &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "\n2 Interactive Data Visualisation - ggiraph methods",
    "text": "2 Interactive Data Visualisation - ggiraph methods\n\n2.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package.\nNotice that the code chunk consists of two parts.\n\nFirst, an ggplot object will be created.\nNext, girafe() of ggiraph will be used to create an interactive svg object.\n\n\nClick to view the code.p &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactivity",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "\n3 Interactivity",
    "text": "3 Interactivity\n\n3.1 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nClick to view the code.exam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactivity---advanced",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactivity---advanced",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "\n4 Interactivity - Advanced",
    "text": "4 Interactivity - Advanced\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n4.1 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\nClick to view the code.tooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\n4.2 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\nClick to view the code.tooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n4.3 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\nClick to view the code.p &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS, tooltip = ID),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\n\n4.4 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\nClick to view the code.p &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n4.5 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\nClick to view the code.p &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n4.6 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\nClick to view the code.exam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\n\n4.7 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\nAppropriate interactive functions of ggiraph will be used to create the multiple views. patchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.\n\nClick to view the code.p1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "\n5 Interactive Data Visualisation - plotly methods!",
    "text": "5 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n\n5.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nClick to view the code.plot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n5.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nClick to view the code.plot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n5.3 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\nClick to view the code.p &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n5.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\nThing to learn from the code chunk:\nhighlight_key() simply creates an object of class crosstalk::SharedData.\n\nClick to view the code.d &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3.1: Programming Interactive Data Visualisation with R",
    "section": "\n6 Interactive Data Visualisation - crosstalk methods!",
    "text": "6 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n6.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n6.2 Linked brushing: crosstalk method\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!.\n\n\nClick to view the code.d &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "",
    "text": "tidyverse, a family of R packages for data science process.\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots.\nggdist for visualising distribution and uncertainty..\n\npacman::p_load(ggdist, ggridges, ggthemes, colorspace, tidyverse)\n\n\n\nexam &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#getting-started",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "",
    "text": "tidyverse, a family of R packages for data science process.\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots.\nggdist for visualising distribution and uncertainty..\n\npacman::p_load(ggdist, ggridges, ggthemes, colorspace, tidyverse)\n\n\n\nexam &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "\n2 Visualising Distribution with Ridgeline Plot",
    "text": "2 Visualising Distribution with Ridgeline Plot\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n2.1 Plotting ridgeline graph: ggridges method\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nClick to view the code.ggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n2.2 Varying fill colors along the x axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nClick to view the code.ggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Student_Score\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n2.3 Mapping the probabilities directly onto colour\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\nClick to view the code.ggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n2.4 Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nClick to view the code.ggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nClick to view the code.ggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-on Exercise 4.1: Visualising Distribution",
    "section": "\n3 Visualising Distribution with Raincloud Plot",
    "text": "3 Visualising Distribution with Raincloud Plot\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, you will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n3.1 Plotting a Half Eye graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nClick to view the code.ggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n3.2 Adding the boxplot with geom_boxplot()\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nClick to view the code.ggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\n3.3 Adding the Dot Plots with stat_dots()\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nClick to view the code.ggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n3.4 Finishing touch\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nClick to view the code.ggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk, DT, ggdist, ggridges, colorspace, gganimate, tidyverse)\n\n\n\nexam &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#getting-started",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk, DT, ggdist, ggridges, colorspace, gganimate, tidyverse)\n\n\n\nexam &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "\n2 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "2 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nClick to view the code.my_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nClick to view the code.knitr::kable(head(my_sum), format = 'html')\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n2.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nClick to view the code.ggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n2.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nClick to view the code.ggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n2.3 Visualizing the uncertainty of point estimates with interactive error bars\nLearning how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nClick to view the code.shared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4.3: Visualising Uncertainty",
    "section": "\n3 Visualising Uncertainty: ggdist package",
    "text": "3 Visualising Uncertainty: ggdist package\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n3.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nClick to view the code.exam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nFor example, in the code chunk below the following arguments are used:\n\nwidth = 0.95\npoint = median\ninterval = qi\n\n\nClick to view the code.exam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n3.2 Visualizing the uncertainty of point estimates: ggdist methods\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\nClick to view the code.exam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nClick to view the code.exam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width = c(0.95, 0.99),\n    .point = median,\n    .interval = qi\n  ) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\"\n  )\n\n\n\n\n\n\n\n\n3.3 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nClick to view the code.exam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\n3.4 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nlibrary(ungeviz)\n\n\nClick to view the code.ggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n3.5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nClick to view the code.ggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html",
    "title": "Hands-on Exercise 5.1: Building Ternary Plot with R",
    "section": "",
    "text": "ggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\n\npacman::p_load('plotly', 'tidyverse', 'ggtern')\n# require(devtools)\n# install_version(\"ggtern\", version = \"3.4.1\", repos = \"http://cran.us.r-project.org\")\n# library(ggtern)\n\n\n\npop_data &lt;- read_csv(\"../../data/respopagsex2000to2018_tidy.csv\") \n\n\nUsing the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\nClick to view the code.#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#getting-started",
    "title": "Hands-on Exercise 5.1: Building Ternary Plot with R",
    "section": "",
    "text": "ggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\n\npacman::p_load('plotly', 'tidyverse', 'ggtern')\n# require(devtools)\n# install_version(\"ggtern\", version = \"3.4.1\", repos = \"http://cran.us.r-project.org\")\n# library(ggtern)\n\n\n\npop_data &lt;- read_csv(\"../../data/respopagsex2000to2018_tidy.csv\") \n\n\nUsing the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\nClick to view the code.#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_1.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 5.1: Building Ternary Plot with R",
    "section": "\n2 Plotting Ternary Diagram with R",
    "text": "2 Plotting Ternary Diagram with R\n\n2.1 Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\nClick to view the code.#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\nClick to view the code.#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n2.2 Plotting an interative ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\nClick to view the code.# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html",
    "title": "Hands-on Exercise 5.3: Visual Multivariate Analysis with Heatmap",
    "section": "",
    "text": "pacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\nwh &lt;- read_csv(\"../../data/WHData-2018.csv\")\n\n\nChange the rows by country name instead of row number by using the code chunk below.\nNotice that the row number has been replaced into the country name.\nrow.names(wh) &lt;- wh$Country\n\nThe data was loaded into a data frame, but it has to be a data matrix to make the heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nClick to view the code.wh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#getting-started",
    "title": "Hands-on Exercise 5.3: Visual Multivariate Analysis with Heatmap",
    "section": "",
    "text": "pacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\nwh &lt;- read_csv(\"../../data/WHData-2018.csv\")\n\n\nChange the rows by country name instead of row number by using the code chunk below.\nNotice that the row number has been replaced into the country name.\nrow.names(wh) &lt;- wh$Country\n\nThe data was loaded into a data frame, but it has to be a data matrix to make the heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nClick to view the code.wh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#static-heatmap",
    "title": "Hands-on Exercise 5.3: Visual Multivariate Analysis with Heatmap",
    "section": "\n2 Static Heatmap",
    "text": "2 Static Heatmap\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nLearning how to plot static heatmaps by using heatmap() of R Stats package.\n\nClick to view the code.wh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nClick to view the code.wh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nClick to view the code.wh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 5.3: Visual Multivariate Analysis with Heatmap",
    "section": "\n3 Creating Interactive Heatmap",
    "text": "3 Creating Interactive Heatmap\n\n3.1 Working with heatmaply\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\n\nClick to view the code.heatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nClick to view the code.heatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n3.2 Data transformation\n\n3.2.1 Scaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nClick to view the code.heatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n3.2.2 Normalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nClick to view the code.heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n3.2.3 Percentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nClick to view the code.heatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n3.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\n\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\n\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\n\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n3.4 Manual approach\n\nClick to view the code.heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n3.5 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nClick to view the code.wh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n\n  \n\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nClick to view the code.wh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nClick to view the code.heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n3.6 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nClick to view the code.heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nClick to view the code.heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nClick to view the code.heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nClick to view the code.heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n3.7 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nClick to view the code.heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n3.8 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\n\nk_row is used to produce 5 groups.\n\nmargins is used to change the top margin to 60 and row margin to 200.\n\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\n\nmain is used to write the main title of the plot.\n\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nClick to view the code.heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "",
    "text": "pacman::p_load(treemap, treemapify, tidyverse) \n\n\n\nrealis2018 &lt;- read_csv(\"../../data/realis2018.csv\")\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\nClick to view the code.realis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%\n\nClick to view the code.realis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#getting-started",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "",
    "text": "pacman::p_load(treemap, treemapify, tidyverse) \n\n\n\nrealis2018 &lt;- read_csv(\"../../data/realis2018.csv\")\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\nClick to view the code.realis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%\n\nClick to view the code.realis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#designing-treemap-with-treemap-package",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "\n2 Designing Treemap with treemap Package",
    "text": "2 Designing Treemap with treemap Package\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n2.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nClick to view the code.realis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n2.2 Using the basic arguments\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\nClick to view the code.treemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\n\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\n\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n2.3 Working with vColor and type arguments\n\nClick to view the code.treemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n2.4 Colours in treemap package\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n2.5 The “value” type treemap\n\nClick to view the code.treemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n2.6 The “manual” type treemap\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\nClick to view the code.treemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\nClick to view the code.treemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n2.7 Treemap Layout\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n2.8 Working with algorithm argument\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\nClick to view the code.treemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n2.9 Using sortID\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\nClick to view the code.treemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "\n3 Designing Treemap using treemapify Package",
    "text": "3 Designing Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n3.1 Designing a basic treemap\n\nClick to view the code.ggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n3.2 Defining hierarchy\n\n3.2.1 Group by Planning Region\n\nClick to view the code.ggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\n3.2.2 Group by Planning Area\n\nClick to view the code.ggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\n3.2.3 Adding boundary line\n\nClick to view the code.ggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_5.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on Exercise 5.5: Treemap Visualisation with R",
    "section": "\n4 Designing Interactive Treemap using d3treeR",
    "text": "4 Designing Interactive Treemap using d3treeR\n\n4.1 Installing d3treeR package\n\n#install.packages(\"devtools\")\nlibrary(devtools)\n\n\n#install_github(\"timelyportfolio/d3treeR\")\nlibrary(d3treeR)\n\n\n4.2 Designing An Interactive Treemap - Step1\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\nClick to view the code.tm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n4.3 Designing An Interactive Treemap - Step2\nThen d3tree() is used to build an interactive treemap.\n\nClick to view the code.d3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_1.html",
    "title": "Hands-on Exercise 7.1: Choropleth Mapping in R",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap[https://cran.r-project.org/web/packages/tmap/] package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\nmpsz &lt;- st_read(dsn = \"../../data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `E:\\kaixx1027\\ISSS608-VAA\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\npopdata &lt;- read_csv(\"../../data/aspatial/respopagesextod2011to2020.csv\")\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\nClick to view the code.popdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`), .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\nClick to view the code.popdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nClick to view the code.mpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nThing to learn from the code chunk above:\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"../../data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_1.html#getting-started",
    "title": "Hands-on Exercise 7.1: Choropleth Mapping in R",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap[https://cran.r-project.org/web/packages/tmap/] package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\nmpsz &lt;- st_read(dsn = \"../../data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `E:\\kaixx1027\\ISSS608-VAA\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\npopdata &lt;- read_csv(\"../../data/aspatial/respopagesextod2011to2020.csv\")\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\nClick to view the code.popdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`), .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\nClick to view the code.popdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nClick to view the code.mpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nThing to learn from the code chunk above:\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"../../data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_1.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_1.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 7.1: Choropleth Mapping in R",
    "section": "\n2 Choropleth Mapping Geospatial Data Using tmap",
    "text": "2 Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\nClick to view the code.tmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n2.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n2.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\nClick to view the code.tm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n2.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n2.2.3 Drawing a choropleth map using tm_fill() and tm_border()\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n2.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n2.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nClick to view the code.summary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n2.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n2.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n2.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n2.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n2.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n2.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nClick to view the code.tmap_style(\"white\")\n\n\n\n2.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\nClick to view the code.tm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\nClick to view the code.tm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n2.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\nClick to view the code.tm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n2.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nClick to view the code.youngmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n2.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\nClick to view the code.tm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html",
    "title": "Hands-on Exercise 7.3: Analytical Mapping",
    "section": "",
    "text": "pacman::p_load(tmap, tidyverse, sf)\n\n\n\nNGA_wp &lt;- read_rds(\"../../data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html#getting-started",
    "title": "Hands-on Exercise 7.3: Analytical Mapping",
    "section": "",
    "text": "pacman::p_load(tmap, tidyverse, sf)\n\n\n\nNGA_wp &lt;- read_rds(\"../../data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 7.3: Analytical Mapping",
    "section": "\n2 Basic Choropleth Mapping",
    "text": "2 Basic Choropleth Mapping\n\n2.1 Visualising distribution of non-functional water point\n\nClick to view the code.p1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\n\nClick to view the code.p2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 7.3: Analytical Mapping",
    "section": "\n3 Choropleth Map for Rates",
    "text": "3 Choropleth Map for Rates\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n3.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nClick to view the code.NGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n3.2 Plotting map of rate\n\nClick to view the code.tm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07_3.html#extreme-value-maps",
    "title": "Hands-on Exercise 7.3: Analytical Mapping",
    "section": "\n4 Extreme Value Maps",
    "text": "4 Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n4.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n4.1.1 Data Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nClick to view the code.NGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\n\nStep 2: Creating customised classification and extracting values\n\nClick to view the code.percent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\nImportant: When variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n4.1.2 Why writing functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n4.1.3 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\n\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n\nClick to view the code.get.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n4.1.4 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\nClick to view the code.percentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n4.1.5 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n4.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nClick to view the code.ggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n4.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\n\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\n\nClick to view the code.boxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n4.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\n\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n\nClick to view the code.get.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n4.2.3 Test drive the newly created function\nLet’s test the newly created function\n\nClick to view the code.var &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n4.2.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nClick to view the code.boxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\n\nClick to view the code.tmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, clock, tidyverse, graphlayouts,readr,dplyr,ggplot2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#getting-started",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, clock, tidyverse, graphlayouts,readr,dplyr,ggplot2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-data",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "\n2 Importing Data",
    "text": "2 Importing Data\n\nGAStech_nodes &lt;- read_csv(\"../../data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"../../data/GAStech_email_edge-v2.csv\")\n\n\n2.1 Wrangling time\n\nClick to view the code.GAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n2.2 Wrangling attributes\n\nClick to view the code.GAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "\n3 Creating network objects using tidygraph",
    "text": "3 Creating network objects using tidygraph\n\n3.1 Using tbl_graph() to build tidygraph data model\n\nClick to view the code.GAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n3.2 Reviewing the output tidygraph’s graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 星期日       5\n2     1     2 星期一       2\n3     1     2 星期二       3\n# ℹ 1,369 more rows\n\n\n\n3.3 Changing the active object\n\nClick to view the code.GAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n 1    40    41 星期六      13\n 2    41    43 星期一      11\n 3    35    31 星期二      10\n 4    40    41 星期一      10\n 5    40    43 星期一      10\n 6    36    32 星期日       9\n 7    40    43 星期六       9\n 8    41    40 星期一       9\n 9    19    15 星期三       8\n10    35    38 星期二       8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-practice---plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-practice---plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "\n4 Plotting Practice - Plotting Static Network Graphs with ggraph package",
    "text": "4 Plotting Practice - Plotting Static Network Graphs with ggraph package\n\n4.1 Plotting a basic network graph\n\nClick to view the code.ggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n4.2 Changing the default network graph theme\n\nClick to view the code.g &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n4.3 Changing the coloring of the plot\n\nClick to view the code.g &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n4.4 Fruchterman and Reingold layout\n\nClick to view the code.g &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n4.5 Modifying network nodes\n\nClick to view the code.g &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n4.6 Modifying edges\n\nClick to view the code.g &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-practice---creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-practice---creating-facet-graphs",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "\n5 Plotting Practice - Creating facet graphs",
    "text": "5 Plotting Practice - Creating facet graphs\n\n5.1 Working with facet_edges()\n\nClick to view the code.set_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n5.2 Working with facet_edges()\n\nClick to view the code.set_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n5.3 A framed facet graph\n\nClick to view the code.set_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n5.4 Working with facet_nodes()\n\nClick to view the code.set_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-practice---network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-practice---network-metrics-analysis",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "\n6 Plotting Practice - Network Metrics Analysis",
    "text": "6 Plotting Practice - Network Metrics Analysis\n\n6.1 Computing centrality indices\n\nClick to view the code.g &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n6.2 Visualising network metrics\n\nClick to view the code.g &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n6.3 Visualising Community\n\nClick to view the code.g &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-practice---building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-practice---building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "\n7 Plotting Practice - Building Interactive Network Graph with visNetwork",
    "text": "7 Plotting Practice - Building Interactive Network Graph with visNetwork\n\n7.1 Data preparation\n\nClick to view the code.GAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n7.2 Plotting the first interactive network graph\n\nClick to view the code.visNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n7.3 Working with layout\n\nClick to view the code.visNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n7.4 Working with visual attributes - Nodes\n\nClick to view the code.GAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n7.5 Working with visual attributes - Edges\n\nClick to view the code.visNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n7.6 Interactivity\n\nClick to view the code.visNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1: Now You See It!",
    "section": "",
    "text": "In this hands-on exercise, two R packages will be used. They are:\n\ntidyverse, and\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1: Now You See It!",
    "section": "",
    "text": "In this hands-on exercise, two R packages will be used. They are:\n\ntidyverse, and\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "title": "In-class Exercise 1: Now You See It!",
    "section": "\n2 Importing PISA data",
    "text": "2 Importing PISA data\nThe code chunk below uses read_sas() of haven to import PISA data into R environment.\n\nstu_qqq &lt;- read_sas(\"../../data/cy08msp_stu_qqq.sas7bdat\")\n\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\n\nwrite_rds(stu_qqq_SG,\"data/stu_qqq_SG.rds\")\n\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3: Interactivity in Visual Analytics",
    "section": "",
    "text": "Critic Figure 5.\n\nClick “here” to view the description of figure 5."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#short-quiz",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#short-quiz",
    "title": "In-class Exercise 3: Interactivity in Visual Analytics",
    "section": "",
    "text": "Critic Figure 5.\n\nClick “here” to view the description of figure 5."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tableau",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tableau",
    "title": "In-class Exercise 3: Interactivity in Visual Analytics",
    "section": "2 Tableau",
    "text": "2 Tableau\nLearning how to create interactive reports and storytelling with Tableau."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5: Shiny Basics",
    "section": "",
    "text": "View the slides and the website to learn more about Shiny."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex07/data/geospatial/MPSZ-2019.html",
    "title": "KAI",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "title": "In-class Exercise 8: Network Data Visualisation and Analysis",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, clock, tidyverse, graphlayouts)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#loading-r-package",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#loading-r-package",
    "title": "In-class Exercise 8: Network Data Visualisation and Analysis",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, clock, tidyverse, graphlayouts)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#dataset",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#dataset",
    "title": "In-class Exercise 8: Network Data Visualisation and Analysis",
    "section": "\n2 Dataset",
    "text": "2 Dataset\n\nGAStech_nodes &lt;- read_csv(\"../../data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"../../data/GAStech_email_edge-v2.csv\")\n\n\n2.1 Data Preparation\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n(),.groups = 'drop') %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 星期日       5\n2     1     2 星期一       2\n3     1     2 星期二       3\n# ℹ 1,369 more rows"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#visualisation",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#visualisation",
    "title": "In-class Exercise 8: Network Data Visualisation and Analysis",
    "section": "\n3 Visualisation",
    "text": "3 Visualisation\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph,\n            layout = 'kk')+ \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph,\n            layout = 'nicely')+ \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = \n                        Department,\n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "",
    "text": "Despite claims of educational excellence in Singapore, skepticism persists, particularly regarding disparities in elite and neighborhood schools and socioeconomic factors. Leveraging 2022 PISA data, this project aims for a succinct Exploratory Data Analysis (EDA) using ggplot2 to reveal performance distribution and explore relationships with schools, gender, and socioeconomic status.\n\n\nDistribution Analysis: Use EDA methods and ggplot2 to visualize math, reading, and science performance distribution; Provide insights into score spread, addressing disparities.\nRelationship Exploration: Investigate academic performance relationships with school types using concise boxplots; Analyze gender-based differences with brief boxplots; Examine socioeconomic impact on academic outcomes, identifying correlations using boxplots.\nLimitations and Focus: Utilize up to five EDA visualizations for clarity; Deliver actionable insights for policymakers based on identified patterns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "",
    "text": "Despite claims of educational excellence in Singapore, skepticism persists, particularly regarding disparities in elite and neighborhood schools and socioeconomic factors. Leveraging 2022 PISA data, this project aims for a succinct Exploratory Data Analysis (EDA) using ggplot2 to reveal performance distribution and explore relationships with schools, gender, and socioeconomic status.\n\n\nDistribution Analysis: Use EDA methods and ggplot2 to visualize math, reading, and science performance distribution; Provide insights into score spread, addressing disparities.\nRelationship Exploration: Investigate academic performance relationships with school types using concise boxplots; Analyze gender-based differences with brief boxplots; Examine socioeconomic impact on academic outcomes, identifying correlations using boxplots.\nLimitations and Focus: Utilize up to five EDA visualizations for clarity; Deliver actionable insights for policymakers based on identified patterns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "\n2 Data Preparation",
    "text": "2 Data Preparation\n\n2.1 Loading R packages\nThe code chunk below uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages installed are\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\nhaven: an R package designed for reading and writing datasets from software like SAS, SPSS, and Stata, into R.\ngridExtra: an R package that extends the grid graphics system.\nggplot2: a widely used R package for creating elegant and informative graphics using the Grammar of Graphics framework.\nplotly: an R package for interactive, web-based charts and dashboards, extending ggplot2 capabilities.\nggridges: an R package extending ggplot2 for concise and effective ridge plots.\n\npacman::p_load(ggrepel, ggthemes, hrbrthemes, patchwork, tidyverse, haven, gridExtra, ggplot2, plotly, ggridges)\n\n\n2.2 Dataset\nOne dataset (Student questionnaire data file) from PISA is provided for the task.\n\nstu_qqq &lt;- read_sas(\"../../data/cy08msp_stu_qqq.sas7bdat\")\n\n\n2.2.1 Data Filtering and Transformation\n\nFilter SGP students record\n\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\n\nCreate new dataset including student’ performance in mathematics, reading, and science and relevant record of their schools, gender and socioeconomic status\n\n\n\nClick to view the code.mathematics &lt;- stu_qqq_SG[, c(\"PV1MATH\", \"PV2MATH\", \"PV3MATH\", \"PV4MATH\", \"PV5MATH\", \"PV6MATH\", \"PV7MATH\", \"PV8MATH\", \"PV9MATH\", \"PV10MATH\")]\n\nreading &lt;- stu_qqq_SG[, c(\"PV1READ\", \"PV2READ\", \"PV3READ\", \"PV4READ\", \"PV5READ\", \"PV6READ\", \"PV7READ\", \"PV8READ\", \"PV9READ\", \"PV10READ\")]\n\nscience &lt;- stu_qqq_SG[, c(\"PV1SCIE\", \"PV2SCIE\", \"PV3SCIE\", \"PV4SCIE\", \"PV5SCIE\", \"PV6SCIE\", \"PV7SCIE\", \"PV8SCIE\", \"PV9SCIE\", \"PV10SCIE\")]\n\nschool &lt;- stu_qqq_SG[, c(\"CNTSCHID\")]\n\ngender &lt;- stu_qqq_SG[, c(\"ST004D01T\")]\n\nschool_education &lt;- stu_qqq_SG[, grep(\"ST005|ST007\", names(stu_qqq_SG), value = TRUE)]\n\nvocational_training &lt;- stu_qqq_SG[, grep(\"ST006|ST008\", names(stu_qqq_SG), value = TRUE)]\n\nhome_possessions &lt;- stu_qqq_SG[, grep(\"ST250|ST251|ST253|ST254|ST255|ST256\", names(stu_qqq_SG), value = TRUE)]\n\n\n\n2.2.2 Data Wrangling\n\n2.2.2.1 Calculate the mean and median for maths, reading, and science\nFor mean values, use the rowMeans function to calculate the average score for each student.\nFor median values, use the apply function to compute the median along rows (students).\nThen calculate the total sum of the average and the median scores for the three subjects for each student.\n\nClick to view the code.# Calculate mean values\nAvg_Math &lt;- rowMeans(mathematics, na.rm = TRUE)\nAvg_Reading &lt;- rowMeans(reading, na.rm = TRUE)\nAvg_Science &lt;- rowMeans(science, na.rm = TRUE)\n# Calculate total sum of mean\nTotal_Avg &lt;- rowSums(cbind(avg_math, avg_reading, avg_science), na.rm = TRUE)\n\n# Calculate median values\nMedian_Math &lt;- apply(mathematics, 1, median, na.rm = TRUE)\nMedian_Reading &lt;- apply(reading, 1, median, na.rm = TRUE)\nMedian_Science &lt;- apply(science, 1, median, na.rm = TRUE)\n# Calculate total sum of mean\nTotal_Median &lt;- rowSums(cbind(median_math, median_reading, median_science), na.rm = TRUE)\n\n\n\n2.2.2.2 Merge into a new table and save\n\nClick to view the code.# Create a new data frame\ncombined &lt;- cbind(stu_qqq_SG[\"CNTSTUID\"], Avg_Math, Avg_Reading, Avg_Science, Total_Avg, Median_Math, Median_Reading, Median_Science, Total_Median, school, gender, school_education, vocational_training, home_possessions)\n\ncolnames(combined)[colnames(combined) == \"CNTSCHID\"] &lt;- \"School\"\n\ncolnames(combined)[colnames(combined) == \"ST004D01T\"] &lt;- \"Gender\"\n\nwrite_rds(combined,\n          \"data/combined.rds\")\n\n\nRead the combined data and check for missing values\n\nClick to view the code.combined &lt;- read_rds(\"data/combined.rds\")\nhead(combined)\n\n\n  \n\n\nClick to view the code.any(is.na(combined))\n\n[1] TRUE\n\n\nAssigning names to variables\n\nClick to view the code.School &lt;- combined$School\n\nGender &lt;- combined$Gender\n\nschool_education &lt;- combined[, grep(\"ST005|ST007\", names(combined), value = TRUE)]\n\nvocational_training &lt;- combined[, grep(\"ST006|ST008\", names(combined), value = TRUE)]\n\nhome_possessions &lt;- combined[, grep(\"ST250|ST251|ST253|ST254|ST255|ST256\", names(combined), value = TRUE)]\n\n\n\n2.2.2.3 Calculate the socioeconomic status\n\nUse the rowSums function to calculate the sum of index of school education and vocational training for each students’ parents.\n\nClick to view the code.# Calculate sum values\nsum_school_education &lt;- rowSums(school_education, na.rm = TRUE)\nsum_vocational_training &lt;- rowSums(vocational_training, na.rm = TRUE)\n\n# Calculate sum of home possessions\nhome_possessions &lt;- home_possessions %&gt;%\n  mutate(sum_home_possessions = rowSums(select(., starts_with(\"ST251Q\"), -matches(\"ST251Q05JA|ST251Q08JA\")), na.rm = TRUE))\nsum_home_possessions &lt;- home_possessions$sum_home_possessions\n\n\nThen sum these aggregated values to calculate socioeconomic status for each student.\nCombining scores from school education, vocational training, and home possessions to calculate a person’s overall socioeconomic status makes sense because socioeconomic status is complex and includes things like education, job skills, and how much someone owns. This method creates a single score that shows a person’s level of education, job abilities, and quality of living, all of which are important parts of their financial and social status.\nSummation is straightforward and the results are easier to interpret. It can also handle zero values and matain scale consistency.\n\nsocioeconomic_status &lt;- rowSums(cbind(sum_school_education, sum_vocational_training, sum_home_possessions), na.rm = TRUE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratary-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratary-data-analysis",
    "title": "Take-home Exercise 1: Creating data visualisation beyond default",
    "section": "\n3 Exploratary Data Analysis",
    "text": "3 Exploratary Data Analysis\n\n3.1 Histograms for Distribution of Scores in Each Subject\n\n\n3 subjects\nMathematics\nReading\nScience\n\n\n\n\nClick to view the code.# Calculate the median and mean outside of the ggplot2 aes function\nmedian_Avg_Math &lt;- median(combined$Avg_Math, na.rm = TRUE)\nmean_Avg_Math &lt;- mean(combined$Avg_Math, na.rm = TRUE)\n\nmedian_Avg_Reading &lt;- median(combined$Avg_Reading, na.rm = TRUE)\nmean_Avg_Reading &lt;- mean(combined$Avg_Reading, na.rm = TRUE)\n\nmedian_Avg_Science &lt;- median(combined$Avg_Science, na.rm = TRUE)\nmean_Avg_Science &lt;- mean(combined$Avg_Science, na.rm = TRUE)\n\n# Histogram for Avg_Math\np1 &lt;- ggplot(combined, aes(x = Avg_Math)) +\n  geom_histogram(bins = 20, fill = \"lightblue\", color = \"grey25\") +\n  geom_vline(xintercept = median_Avg_Math, color = \"blue\", linetype = \"dashed\") +\n  geom_vline(xintercept = mean_Avg_Math, color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = median_Avg_Math, y = Inf, label = paste(\"Median:\", round(median_Avg_Math, 2)), vjust = 2, hjust = -1.1, color = \"blue\") +\n  annotate(\"text\", x = mean_Avg_Math, y = Inf, label = paste(\"Mean:\", round(mean_Avg_Math, 2)), vjust = 1, hjust = 1.5, color = \"red\") +\n  ggtitle(\"Histogram of Avg Math Scores\") +\n  xlab(\"Average Math Score\") +\n  ylab(\"count\") +\n  theme_minimal()\n\np2 &lt;- ggplot(combined, aes(x = Avg_Reading)) +\n  geom_histogram(bins = 20, fill = \"lightgreen\", color = \"grey25\") +\n  geom_vline(xintercept = median_Avg_Reading, color = \"blue\", linetype = \"dashed\") +\n  geom_vline(xintercept = mean_Avg_Reading, color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = median_Avg_Reading, y = Inf, label = paste(\"Median:\", round(median_Avg_Reading, 2)), vjust = 2, hjust = -1, color = \"blue\") +\n  annotate(\"text\", x = mean_Avg_Reading, y = Inf, label = paste(\"Mean:\", round(mean_Avg_Reading, 2)), vjust = 1, hjust = 1.5, color = \"red\") +\n  ggtitle(\"Histogram of Avg Reading Scores\") +\n  xlab(\"Average Reading Score\") +\n  ylab(\"count\") +\n  theme_minimal()\n\np3 &lt;- ggplot(combined, aes(x = Avg_Science)) +\n  geom_histogram(bins = 20, fill = \"lightcoral\", color = \"grey25\") +\n  geom_vline(xintercept = median_Avg_Science, color = \"blue\", linetype = \"dashed\") +\n  geom_vline(xintercept = mean_Avg_Science, color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\", x = median_Avg_Science, y = Inf, label = paste(\"Median:\", round(median_Avg_Science, 2)), vjust = 2, hjust = -1, color = \"blue\") +\n  annotate(\"text\", x = mean_Avg_Science, y = Inf, label = paste(\"Mean:\", round(mean_Avg_Science, 2)), vjust = 1, hjust = 1.5, color = \"red\") +\n  ggtitle(\"Histogram of Avg Science Scores\") +\n  xlab(\"Average Science Score\") +\n  ylab(\"count\") +\n  theme_minimal()\n\ngrid.arrange(p1, p2, p3, ncol = 1)\n\n\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(data = combined, \n             aes(x = Avg_Math)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(data=combined, \n             aes(x = Avg_Reading)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Reading scores\") \n\n\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(data=combined, \n             aes(x = Avg_Science)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Science scores\") \n\n\n\n\n\n\n\n\n\n\n\nDistributions for math, reading, and science are bit left-skewed. This may due to that the assessments is challenging and more students are scoring towards the lower end.\nThe closeness of means to median indicates that while distributions are skewed, extreme low scores are not predominant.\nScore distributions are centrally peaked around 500-600. This indicates a standard performance level of the population.\n\nWe can further study the relationship between scores and some family economic status, gender, or schools.\n\n3.2 Performance Comparison by Gender\n‘1’ represents girls and ‘2’ represents boys in the ‘Gender’ column\n\n\n3 subjects\nMathematics\nReading\nScience\n\n\n\n\nClick to view the code.combined$Gender &lt;- factor(Gender, levels = c(1, 2), labels = c(\"Girl\", \"Boy\"))\n\n# Density plot for Mathematics\np1 &lt;- ggplot(combined, aes(x = Avg_Math, fill = Gender)) +\n  geom_density(alpha = 0.5) +\n  ggtitle(\"Density Plot of Avg Math Scores by Gender\") +\n  xlab(\"Average Math Score\") +\n  ylab(\"Density\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"Girl\" = \"pink\", \"Boy\" = \"slateblue\"))\n\n# Density plot for Reading\np2 &lt;- ggplot(combined, aes(x = Avg_Reading, fill = Gender)) +\n  geom_density(alpha = 0.5) +\n  ggtitle(\"Density Plot of Avg Reading Scores by Gender\") +\n  xlab(\"Average Reading Score\") +\n  ylab(\"Density\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"Girl\" = \"pink\", \"Boy\" = \"slateblue\"))\n\n# Density plot for Science\np3 &lt;- ggplot(combined, aes(x = Avg_Science, fill = Gender)) +\n  geom_density(alpha = 0.5) +\n  ggtitle(\"Density Plot of Avg Science Scores by Gender\") +\n  xlab(\"Average Science Score\") +\n  ylab(\"Density\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"Girl\" = \"pink\", \"Boy\" = \"slateblue\"))\n\n# Combining the plots into one image for easy comparison\ngrid.arrange(p1, p2, p3, ncol = 1)\n\n\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(data = combined, aes(x = Avg_Math, color = Gender)) +\n  geom_line(stat = \"density\", size = 1, aes(y = after_stat(density)), alpha = 0.5) +\n  ggtitle(\"Distribution of Math Scores by Gender\") +\n  xlab(\"Average Math Score\") +\n  ylab(\"Density\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Girl\" = \"pink\", \"Boy\" = \"slateblue\"))\n\n\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(data = combined, aes(x = Avg_Reading, color = Gender)) +\n  geom_line(stat = \"density\", size = 1, aes(y = after_stat(density)), alpha = 0.5) +\n  ggtitle(\"Distribution of Reading Scores by Gender\") +\n  xlab(\"Average Reading Score\") +\n  ylab(\"Density\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Girl\" = \"pink\", \"Boy\" = \"slateblue\"))\n\n\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(data = combined, aes(x = Avg_Science, color = Gender)) +\n  geom_line(stat = \"density\", size = 1, aes(y = after_stat(density)), alpha = 0.5) +\n  ggtitle(\"Distribution of Science Scores by Gender\") +\n  xlab(\"Average Science Score\") +\n  ylab(\"Density\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"Girl\" = \"pink\", \"Boy\" = \"slateblue\"))\n\n\n\n\n\n\n\n\n\n\n\nIn math and science, the peak of the boys’ density curve is slightly to the right of the girls’. This indicates that boys tend to have higher average scores in math and science.\nFor reading, the peak of the girls’ density curve is to the right of the boys’. This means that girls have better performance in reading compared with boys.\nHowever, the curves overlap significantly across all subjects. This shows that the difference in gender is not so significant as expected.\n\nThe discovery conform to peoples common sense, although the difference in gender is not so large.\n\n3.3 Performance Comparison by School\n\n\n3 subjects\nMathematics\nReading\nScience\n\n\n\n\nClick to view the code.# Scatter plot for Avg Math Score vs School ID\np1 &lt;- ggplot(combined, aes(x = School, y = Avg_Math)) +\n  geom_point(aes(color = School), alpha = 0.6) +\n  ggtitle(\"Scatter Plot of Avg Math Scores by School ID\") +\n  xlab(\"School ID\") +\n  ylab(\"Average Math Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n# Scatter plot for Avg Reading Score vs School ID\np2 &lt;- ggplot(combined, aes(x = School, y = Avg_Reading)) +\n  geom_point(aes(color = School), alpha = 0.6) +\n  ggtitle(\"Scatter Plot of Avg Reading Scores by School ID\") +\n  xlab(\"School ID\") +\n  ylab(\"Average Reading Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n# Scatter plot for Avg Science Score vs School ID\np3 &lt;- ggplot(combined, aes(x = School, y = Avg_Science)) +\n  geom_point(aes(color = School), alpha = 0.6) +\n  ggtitle(\"Scatter Plot of Avg Science Scores by School ID\") +\n  xlab(\"School ID\") +\n  ylab(\"Average Science Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n# Plotting all three scatter plots in a grid for comparison\ngrid.arrange(p1, p2, p3, ncol = 1)\n\n\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(data=combined, aes(x = School, y = Avg_Math)) +\n  geom_point(aes(color = School), alpha = 0.6) +\n  ggtitle(\"Scatter Plot of Avg Math Scores by School ID\") +\n  xlab(\"School ID\") +\n  ylab(\"Average Math Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(data=combined, aes(x = School, y = Avg_Reading)) +\n  geom_point(aes(color = School), alpha = 0.6) +\n  ggtitle(\"Scatter Plot of Avg Reading Scores by School ID\") +\n  xlab(\"School ID\") +\n  ylab(\"Average Reading Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(data=combined, aes(x = School, y = Avg_Science)) +\n  geom_point(aes(color = School), alpha = 0.6) +\n  ggtitle(\"Scatter Plot of Avg Science Scores by School ID\") +\n  xlab(\"School ID\") +\n  ylab(\"Average Science Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nThe first set of scatter plots shows a wide distribution of average scores across schools, with no clear pattern based on school ID.\n\n\n\nPairwise Comparison\nMathematics\nReading\nScience\n\n\n\n\nClick to view the code.# Compute the average of average scores for each school\nschool_avg_scores &lt;- combined %&gt;%\n  group_by(School) %&gt;%\n  summarise(\n    Avg_Math_Score = mean(Avg_Math, na.rm = TRUE),\n    Avg_Reading_Score = mean(Avg_Reading, na.rm = TRUE),\n    Avg_Science_Score = mean(Avg_Science, na.rm = TRUE)\n  ) %&gt;%\n  ungroup()\n\n# Scatter plot for Average Math vs. Average Reading Scores for each School\np_math_reading &lt;- ggplot(school_avg_scores, aes(x = Avg_Math_Score, y = Avg_Reading_Score)) +\n  geom_point(aes(color = School), alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Math vs. Reading\") +\n  xlab(\"Average Math Score\") +\n  ylab(\"Average Reading Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Scatter plot for Average Math vs. Average Science Scores for each School\np_math_science &lt;- ggplot(school_avg_scores, aes(x = Avg_Math_Score, y = Avg_Science_Score)) +\n  geom_point(aes(color = School), alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Math vs. Science\") +\n  xlab(\"Average Math Score\") +\n  ylab(\"Average Science Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Scatter plot for Average Reading vs. Average Math Scores for each School\np_reading_math &lt;- ggplot(school_avg_scores, aes(x = Avg_Reading_Score, y = Avg_Math_Score)) +\n  geom_point(aes(color = School), color = \"coral\", alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Reading vs. Math\") +\n  xlab(\"Average Reading Score\") +\n  ylab(\"Average Math Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Scatter plot for Average Reading vs. Average Science Scores for each School\np_reading_science &lt;- ggplot(school_avg_scores, aes(x = Avg_Reading_Score, y = Avg_Science_Score)) +\n  geom_point(aes(color = School), color = \"coral\", alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Reading vs. Science\") +\n  xlab(\"Average Reading Score\") +\n  ylab(\"Average Science Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Scatter plot for Average Science vs. Average Math Scores for each School\np_science_math &lt;- ggplot(school_avg_scores, aes(x = Avg_Science_Score, y = Avg_Math_Score)) +\n  geom_point(aes(color = School), color = \"firebrick\", alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Science vs. Math\") +\n  xlab(\"Average Science Score\") +\n  ylab(\"Average Math Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Scatter plot for Average Science vs. Average Reading Scores for each School\np_science_reading &lt;- ggplot(school_avg_scores, aes(x = Avg_Science_Score, y = Avg_Reading_Score)) +\n  geom_point(aes(color = School), color = \"firebrick\", alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Science vs. Reading\") +\n  xlab(\"Average Science Score\") +\n  ylab(\"Average Reading Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Plotting both scatter plots\ngridExtra::grid.arrange(p_math_reading, p_reading_math, p_science_math, p_math_science, p_reading_science, p_science_reading, ncol = 3, nrow = 2)\n\n\n\n\n\n\n\n\n\n\nClick to view the code.# Scatter plot for Average Math vs. Average Reading Scores for each school\np_math_reading &lt;- ggplot(school_avg_scores, aes(x = Avg_Math_Score, y = Avg_Reading_Score)) +\n  geom_point(aes(color = School), alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Average Math vs. Average Reading Scores by School\") +\n  xlab(\"Average Math Score\") +\n  ylab(\"Average Reading Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Scatter plot for Average Math vs. Average Science Scores for each School\np_math_science &lt;- ggplot(school_avg_scores, aes(x = Avg_Math_Score, y = Avg_Science_Score)) +\n  geom_point(aes(color = School), alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Average Math vs. Average Science Scores by School\") +\n  xlab(\"Average Math Score\") +\n  ylab(\"Average Science Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Plotting both scatter plots\ngridExtra::grid.arrange(p_math_reading, p_math_science, nrow = 2)\n\n\n\n\n\n\n\n\n\n\nClick to view the code.# Scatter plot for Average Reading vs. Average Math Scores for each School\np_reading_math &lt;- ggplot(school_avg_scores, aes(x = Avg_Reading_Score, y = Avg_Math_Score)) +\n  geom_point(aes(color = School), alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Average Reading vs. Average Math Scores by School\") +\n  xlab(\"Average Reading Score\") +\n  ylab(\"Average Math Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Scatter plot for Average Reading vs. Average Science Scores for each School\np_reading_science &lt;- ggplot(school_avg_scores, aes(x = Avg_Reading_Score, y = Avg_Science_Score)) +\n  geom_point(aes(color = School), alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Average Reading vs. Average Science Scores by School\") +\n  xlab(\"Average Reading Score\") +\n  ylab(\"Average Science Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Plotting both scatter plots\ngridExtra::grid.arrange(p_reading_math, p_reading_science, nrow = 2)\n\n\n\n\n\n\n\n\n\n\nClick to view the code.# Scatter plot for Average Science vs. Average Math Scores for each School\np_science_math &lt;- ggplot(school_avg_scores, aes(x = Avg_Science_Score, y = Avg_Math_Score)) +\n  geom_point(aes(color = School), alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Average Science vs. Average Math Scores by School\") +\n  xlab(\"Average Science Score\") +\n  ylab(\"Average Math Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Scatter plot for Average Science vs. Average Reading Scores for each School\np_science_reading &lt;- ggplot(school_avg_scores, aes(x = Avg_Science_Score, y = Avg_Reading_Score)) +\n  geom_point(aes(color = School), alpha = 0.7) +\n  geom_smooth(formula = 'y ~ x', method = lm, color = \"black\", linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Average Science vs. Average Reading Scores by School\") +\n  xlab(\"Average Science Score\") +\n  ylab(\"Average Reading Score\") +\n  theme(legend.position = \"none\")  # Omitting the legend for clarity\n\n# Plotting both scatter plots\ngridExtra::grid.arrange(p_science_math, p_science_reading, nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\nThe second set of plots fixes School ID and try to compare scores of different subjects within each School. These plots reveal a strong positive correlation between average scores across all subjects, indicating that Schools with high performance in one subject tend to perform well in others too.\n\nThis suggests that factors influencing School performance may be systemic rather than subject specific. Schools with higher performance on a specific subject also performs well on other subjects.\n\n3.4 Performance Comparison by Socioeconomic Status\nConstructing pairwise heatmap plots for home possessions, education level, and vocational training level, vesus the total average score.\n\n\nSchool Education v.s. Home Possessions\nHome Possessions v.s. Vocational Training\nVocational Training v.s. School Education\n\n\n\n\nClick to view the code.# Binning numeric variables\nbin_school_education &lt;- cut(sum_school_education, breaks = 5, labels = FALSE)\nbin_home_possessions &lt;- cut(sum_home_possessions, breaks = 5, labels = FALSE)\n\n# Converting the bins to factor\nbin_school_education &lt;- as.factor(bin_school_education)\nbin_home_possessions &lt;- as.factor(bin_home_possessions)\n\n# Creating the heatmap\nggplot(combined, aes(x = bin_school_education, y = bin_home_possessions, fill = Total_Avg)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"lightblue\", high = \"lightcoral\") +\n  labs(x = \"School Education (Binned)\", y = \"Home Possessions (Binned)\", title = \"Heatmap of Total Average by Binned School Education and Home Possessions\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nClick to view the code.# Binning numeric variables\nbin_home_possessions &lt;- cut(sum_home_possessions, breaks = 5, labels = FALSE)\nbin_vocational_training &lt;- cut(sum_vocational_training, breaks = 5, labels = FALSE)\n\n# Converting the bins to factor\nbin_home_possessions &lt;- as.factor(bin_home_possessions)\nbin_vocational_training &lt;- as.factor(bin_vocational_training)\n\n# Creating the heatmap\nggplot(combined, aes(x = bin_home_possessions, y = bin_vocational_training, fill = Total_Avg)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"lightblue\", high = \"lightcoral\") +\n  labs(x = \"Home Possessions (Binned)\", y = \"Vocational Training (Binned)\", title = \"Heatmap of Total Average by Binned Home Possessions and Vocational Training\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nClick to view the code.# Binning numeric variables\nbin_vocational_training &lt;- cut(sum_vocational_training, breaks = 5, labels = FALSE)\nbin_school_education &lt;- cut(sum_school_education, breaks = 5, labels = FALSE)\n\n# Converting the bins to factor\nbin_vocational_training &lt;- as.factor(bin_vocational_training)\nbin_school_education &lt;- as.factor(bin_school_education)\n\n# Creating the heatmap\nggplot(combined, aes(x = bin_vocational_training, y = bin_school_education, fill = Total_Avg)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"lightblue\", high = \"lightcoral\") +\n  labs(x = \"Vocational Training (Binned)\", y = \"School Education (Binned)\", title = \"Heatmap of Total Average by Vocational Training and School Education\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nGenerally speaking, there is a positive correlation between home possessions and total average score given a certain level of education. Similarly, given a level of home possessions, there is a positive correlation between education and total average score. This is in line with our expectations.\nSome blank areas on the heatmap represent missing data.\nStudents whose parents have a medium level of home possessions but higher education have the highest average scores.\n\nTotal average score is related to arbitrary two of the three indexes.\n\n\nSocieconomic Status\nSchool Education\nHome Possessions\nVocational Training\n\n\n\n\nClick to view the code.combined &lt;- combined %&gt;%\n  mutate(socioeconomic_group = ntile(socioeconomic_status, 5))\n\n# Plot the density of total_avg scores for each socioeconomic group in a column layout\nggplot(combined, aes(x = Total_Avg, fill = factor(socioeconomic_group))) + \n  geom_density(alpha = 0.5, color = \"white\", size = 0.5) + \n  labs(title = \"Density of Total Average Scores for Socioeconomic Groups\", \n       x = \"Total Average Score\", \n       y = \"Density\",\n       fill = \"Socioeconomic Group\") + \n  theme_minimal() +\n  theme(legend.position = \"right\",\n        panel.grid.major = element_line(color = \"lightgray\", linetype = \"dashed\"),) +\n  facet_wrap(~socioeconomic_group, scales = \"free_y\", ncol = 1)\n\n\n\n\n\n\n\n\n\n\nClick to view the code.combined &lt;- combined %&gt;%\n  mutate(school_education_group = ntile(sum_school_education, 5))\n\nggplot(combined, aes(x = Total_Avg, fill = factor(school_education_group))) + \n  geom_density(alpha = 0.5, color = \"white\", size = 0.5) + \n  labs(title = \"Density of Total Average Scores for School Education Groups\", \n       x = \"Total Average Score\", \n       y = \"Density\",\n       fill = \"School Education Group\") + \n  theme_minimal() +\n  theme(legend.position = \"right\",\n        panel.grid.major = element_line(color = \"lightgray\", linetype = \"dashed\"),) +\n  facet_wrap(~school_education_group, scales = \"free_y\", ncol = 1)\n\n\n\n\n\n\n\n\n\n\nClick to view the code.combined &lt;- combined %&gt;%\n  mutate(home_possessions_group = ntile(sum_home_possessions, 5))\n\nggplot(combined, aes(x = Total_Avg, fill = factor(home_possessions_group))) + \n  geom_density(alpha = 0.5, color = \"white\", size = 0.5) + \n  labs(title = \"Density of Total Average Scores for Home Possessions Groups\", \n       x = \"Total Average Score\", \n       y = \"Density\",\n       fill = \"Home Possessions Group\") + \n  theme_minimal() +\n  theme(legend.position = \"right\",\n        panel.grid.major = element_line(color = \"lightgray\", linetype = \"dashed\"),) +\n  facet_wrap(~home_possessions_group, scales = \"free_y\", ncol = 1)\n\n\n\n\n\n\n\n\n\n\nClick to view the code.combined &lt;- combined %&gt;%\n  mutate(vocational_training_group = ntile(sum_vocational_training, 5))\n\nggplot(combined, aes(x = Total_Avg, fill = factor(vocational_training_group))) + \n  geom_density(alpha = 0.5, color = \"white\", size = 0.5) + \n  labs(title = \"Density of Total Average Scores for Vocational Training Groups\", \n       x = \"Total Average Score\", \n       y = \"Density\",\n       fill = \"Vocational Training Group\") + \n  theme_minimal() +\n  theme(legend.position = \"right\",\n        panel.grid.major = element_line(color = \"lightgray\", linetype = \"dashed\"),) +\n  facet_wrap(~vocational_training_group, scales = \"free_y\", ncol = 1)\n\n\n\n\n\n\n\n\n\n\n\nFrom level 1 to level 3, we see that as families have more money and resources, their children’s school scores usually get better. This improvement might be because these families can afford better learning materials, better schools, or more help with studies.\nHowever, once they reach a higher income level (level 3 to level 5), making even more money doesn’t seem to help the kids’ scores increase much further.\n\nThis suggests that after a certain point, just having more resources doesn’t continue to boost school performance in the same way."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "",
    "text": "The impact of climate change on weather patterns is a growing concern globally, with implications for various sectors including agriculture, infrastructure, and public health.\nIn this project, we aim to explore historical weather trends in Singapore using data obtained from the Meteorological Service Singapore website. By leveraging visual analytics techniques, we seek to provide insights into rainfall variations over the past four decades (1983, 1993, 2003, 2013, and 2023), with a focus on validating projections regarding temperature increases and changes in wet and dry seasons.\n\n\nAnalyze historical daily rainfall data from selected weather stations in Singapore.\nCreate data visualizations to illustrate trends and patterns in weather data for the specified months of the chosen years.\nApply interactive techniques to enhance user engagement and facilitate data exploration.\nValidate projections regarding changes in wet and dry seasons as stated in the office report."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "",
    "text": "The impact of climate change on weather patterns is a growing concern globally, with implications for various sectors including agriculture, infrastructure, and public health.\nIn this project, we aim to explore historical weather trends in Singapore using data obtained from the Meteorological Service Singapore website. By leveraging visual analytics techniques, we seek to provide insights into rainfall variations over the past four decades (1983, 1993, 2003, 2013, and 2023), with a focus on validating projections regarding temperature increases and changes in wet and dry seasons.\n\n\nAnalyze historical daily rainfall data from selected weather stations in Singapore.\nCreate data visualizations to illustrate trends and patterns in weather data for the specified months of the chosen years.\nApply interactive techniques to enhance user engagement and facilitate data exploration.\nValidate projections regarding changes in wet and dry seasons as stated in the office report."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "\n2 Loading R packages",
    "text": "2 Loading R packages\nThe original design will then be remade using data visualization design principles and best practices using ggplot2, its extensions, and tidyverse packages.\n\npacman::p_load(cowplot, DT, dplyr, ggridges, ggiraph, ggrepel, ggthemes, gridExtra, ggplot2, gifski, gapminder, gganimate, heatmaply, hrbrthemes, haven, patchwork, plotly, patchwork, readr, tidyverse, viridis)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dataset",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#dataset",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "\n3 Dataset",
    "text": "3 Dataset\nThe original dataset (historical daily temperature or rainfall data) was downloaded from Meteorological Service Singapore.\nSelecting the daily weather records of jul and dec from the years 1983, 1993, 2003, 2013, and 2023, data from the Changi Meteorological Station have been chosen and downloaded for analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "\n4 Data Preparation",
    "text": "4 Data Preparation\n\n4.1 Data Loading and Combination\nThe code reads data from CSV files corresponding to dec of the years 1983, 1993, 2003, 2013, and 2023, using the ISO-8859-4 and UTF-8 encoding to interpret text data from the files.\nNext, the separate data frames are merged together into two data frames called “dec” and “jul” accordingly.\n\nClick to view the code.data198312 &lt;- read_csv(\"../../data/DAILYDATA_S24_198312.csv\", locale = locale(encoding = \"ISO-8859-4\"))\ndata199312 &lt;- read_csv(\"../../data/DAILYDATA_S24_199312.csv\", locale = locale(encoding = \"ISO-8859-4\"))\ndata200312 &lt;- read_csv(\"../../data/DAILYDATA_S24_200312.csv\", locale = locale(encoding = \"ISO-8859-4\"))\ndata201312 &lt;- read_csv(\"../../data/DAILYDATA_S24_201312.csv\", locale = locale(encoding = \"ISO-8859-4\"))\ndata202312 &lt;- read_csv(\"../../data/DAILYDATA_S24_202312.csv\", locale = locale(encoding = \"UTF-8\"))\n\ndec &lt;- bind_rows(data198312, data199312, data200312, data201312, data202312)\n\ndata198307 &lt;- read_csv(\"../../data/DAILYDATA_S24_198307.csv\", locale = locale(encoding = \"ISO-8859-4\"))\ndata199307 &lt;- read_csv(\"../../data/DAILYDATA_S24_199307.csv\", locale = locale(encoding = \"ISO-8859-4\"))\ndata200307 &lt;- read_csv(\"../../data/DAILYDATA_S24_200307.csv\", locale = locale(encoding = \"ISO-8859-4\"))\ndata201307 &lt;- read_csv(\"../../data/DAILYDATA_S24_201307.csv\", locale = locale(encoding = \"ISO-8859-4\"))\ndata202307 &lt;- read_csv(\"../../data/DAILYDATA_S24_202307.csv\", locale = locale(encoding = \"UTF-8\"))\n\njul &lt;- bind_rows(data198307, data199307, data200307, data201307, data202307)\n\n\nNext step, remove blank data columns.\n\nClick to view the code.dec_blank_cols &lt;- grep(\"Highest\", names(dec))\ndec_noblank &lt;- subset(dec, select = -dec_blank_cols)\n\njul_blank_cols &lt;- grep(\"Highest\", names(jul))\njul_noblank &lt;- subset(jul, select = -jul_blank_cols)\n\n\nFinally, save the data for jul and dec to separate RDS files.\n\nClick to view the code.write_rds(dec_noblank,\"data/dec.rds\")\nwrite_rds(jul_noblank,\"data/jul.rds\")\n\n\nRead the combined data and check for missing values\n\nClick to view the code.dec &lt;- read_rds(\"data/dec.rds\")\nhead(dec)\n\n\n  \n\n\nClick to view the code.any(is.na(dec))\n\n[1] FALSE\n\nClick to view the code.jul &lt;- read_rds(\"data/jul.rds\")\nhead(jul)\n\n\n  \n\n\nClick to view the code.any(is.na(jul))\n\n[1] FALSE\n\n\n\n4.2 Data Wrangling\nCalculate the differences between the data for July and December.\n\nClick to view the code.july &lt;- subset(jul, Month == 7)\ndecember &lt;- subset(dec, Month == 12)\n\njuly &lt;- july[, !(names(july) %in% \"Month\")]\ndecember &lt;- december[, !(names(december) %in% \"Month\")]\n\ndiff &lt;- data.frame(\n  Station = july$Station,\n  Year = july$Year,\n  Day = july$Day,\n  Daily_Rainfall_Total_mm = december$`Daily Rainfall Total (mm)` - july$`Daily Rainfall Total (mm)`,\n  Mean_Temperature_C = december$`Mean Temperature (°C)` - july$`Mean Temperature (°C)`,\n  Maximum_Temperature_C = december$`Maximum Temperature (°C)` - july$`Maximum Temperature (°C)`,\n  Minimum_Temperature_C = december$`Minimum Temperature (°C)` - july$`Minimum Temperature (°C)`,\n  Mean_Wind_Speed_km_h = december$`Mean Wind Speed (km/h)` - july$`Mean Wind Speed (km/h)`,\n  Max_Wind_Speed_km_h = december$`Max Wind Speed (km/h)` - july$`Max Wind Speed (km/h)`\n)\n\nhead(diff)\n\n\n  \n\n\n\nCalculate the average and median rainfall for July and December each year.\n\njul_ave &lt;- jul %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    AverageRainfall = mean(`Daily Rainfall Total (mm)`, na.rm = TRUE))\njul_med &lt;- jul %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    MedianRainfall = median(`Daily Rainfall Total (mm)`, na.rm = TRUE))\n\ndec_ave &lt;- dec %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    AverageRainfall = mean(`Daily Rainfall Total (mm)`, na.rm = TRUE))\ndec_med &lt;- dec %&gt;%\n  group_by(Year) %&gt;%\n  summarise(\n    MedianRainfall = median(`Daily Rainfall Total (mm)`, na.rm = TRUE))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-visualisation",
    "title": "Take-home Exercise 3: Be Weatherwise or Otherwise",
    "section": "\n5 Data Visualisation",
    "text": "5 Data Visualisation\n\n5.1 Visualization for Wet Season and Dry Season\nWe have selected December to represent the wet season and July to represent the dry season for data presentation.\nUsing density plots to display the rainfall situation for different months over the past 40 years.\n\nClick to view the code.ggplot(dec, \n       aes(x = `Daily Rainfall Total (mm)`, \n           y = factor(Year))) +\n  geom_density_ridges(\n    scale = 2,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    color = \"white\",\n    fill = \"#4477AA\",\n    alpha = 0.6\n  ) +\n  labs(\n    title = \"Changi: Distribution of Daily Rainfall in December (1983-2023)\",\n    x = \"Daily Rainfall (mm)\",\n    y = \"Year\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    axis.title.y = element_text(margin = margin(r = 20)),\n    panel.background = element_rect(fill = \"#F0F0F0\"),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\nClick to view the code.ggplot(jul, \n       aes(x = `Daily Rainfall Total (mm)`, \n           y = factor(Year))) +\n  geom_density_ridges(\n    scale = 2,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    color = \"white\",\n    fill = \"#FFB6C1\",\n    alpha = 0.6\n  ) +\n  labs(\n    title = \"Changi: Distribution of Daily Rainfall in July (1983-2023)\",\n    x = \"Daily Rainfall (mm)\",\n    y = \"Year\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    axis.title.y = element_text(margin = margin(r = 20)),\n    panel.background = element_rect(fill = \"#F0F0F0\"),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\nThrough these two charts, we can clearly see that both the total rainfall amount and the rainfall frequency are much greater during the rainy season compared to the dry season.\n\n5.2 Enhancing Engagement through Interactive Techniques\nNext, we will employ interactive techniques to enrich the user experience of our data visualizations, allowing users to delve deeper into the data. This will facilitate a better understanding of the distinctions between the wet and dry seasons, enabling users to conduct more comprehensive exploration and analysis according to their interests.\n\n\nJuly\nDecember\n\n\n\n\nClick to view the code.p_jul &lt;- ggplot(jul, aes(x = Year, y = `Daily Rainfall Total (mm)`)) +\n  geom_point(aes(color = `Daily Rainfall Total (mm)`, text = paste('Day:', Day)), alpha = 0.7, size = 2) +\n  geom_line(data = jul_ave, aes(x = Year, y = AverageRainfall), \n            color = \"seagreen3\", linetype = \"dotted\") +\n  geom_line(data = jul_med, aes(x = Year, y = MedianRainfall), \n            color = \"palevioletred\", linetype = \"dotted\") +\n  geom_point(data = jul_ave, aes(x = Year, y = AverageRainfall), \n             color = \"seagreen3\", size = 1) + \n  geom_point(data = jul_med, aes(x = Year, y = MedianRainfall), \n             color = \"palevioletred\", size = 1) + \n  labs(title = \"Changi: Daily Rainfall in July (1983-2023)\",\n       x = \"Year\",\n       y = \"Daily Rainfall Total (mm)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(breaks = seq(1983, 2023, by = 10)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  annotate(\"text\", x = 2000, y = 4, label = \"Average\", color = \"seagreen3\") +\n  annotate(\"text\", x = 2000, y = 1, label = \"Median\", color = \"palevioletred\")\n\nggplotly(p_jul) %&gt;%\n  layout(hovermode = 'closest') %&gt;%\n  config(displayModeBar = FALSE)\n\n\n\n\n\n\n\n\nClick to view the code.p_dec &lt;- ggplot(dec, aes(x = Year, y = `Daily Rainfall Total (mm)`)) +\n  geom_point(aes(color = `Daily Rainfall Total (mm)`, text = paste('Day:', Day)), alpha = 0.7, size = 2) +\n  geom_line(data = dec_ave, aes(x = Year, y = AverageRainfall), \n            color = \"seagreen3\", linetype = \"dotted\") +\n  geom_line(data = dec_med, aes(x = Year, y = MedianRainfall), \n            color = \"palevioletred\", linetype = \"dotted\") +\n  geom_point(data = dec_ave, aes(x = Year, y = AverageRainfall), \n             color = \"seagreen3\", size = 1) + \n  geom_point(data = dec_med, aes(x = Year, y = MedianRainfall), \n             color = \"palevioletred\", size = 1) + \n  labs(title = \"Changi: Daily Rainfall in December (1983-2023)\",\n       x = \"Year\",\n       y = \"Daily Rainfall Total (mm)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(breaks = seq(1983, 2023, by = 10)) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  annotate(\"text\", x = 2000, y = 15, label = \"Average\", color = \"seagreen3\") +\n  annotate(\"text\", x = 2000, y = -5, label = \"Median\", color = \"palevioletred\")\n\nggplotly(p_dec) %&gt;%\n  layout(hovermode = 'closest') %&gt;%\n  config(displayModeBar = FALSE)\n\n\n\n\n\n\n\n\nWe then merged the data for July and December, clearly illustrating that July occupies the lower portion while December dominates the upper part. This indicates that, on average, December experiences significantly higher rainfall than July.\n\nClick to view the code.combined &lt;- bind_rows(\n  mutate(jul, Month = \"July\"),\n  mutate(dec, Month = \"December\")\n)\n\np_combined &lt;- ggplot(combined, aes(x = Year, y = `Daily Rainfall Total (mm)`, color = Month)) +\n  geom_point(alpha = 0.7, size = 2) +\n  labs(title = \"Changi: Daily Rainfall (1983-2023)\",\n       x = \"Year\",\n       y = \"Daily Rainfall Total (mm)\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  scale_color_manual(values = c(\"July\" = \"#FFB6C1\", \"December\" = \"#4477AA\")) +\n  scale_x_continuous(breaks = seq(1983, 2023, by = 10))\n\nggplotly(p_combined) %&gt;%\n  layout(hovermode = 'closest') %&gt;%\n  config(displayModeBar = FALSE)\n\n\n\n\n\n\n5.3 Validating Predictions on Seasonal Changes\nFollowing the calculation of the difference in rainfall between the wet and dry seasons, we constructed box plots to illustrate the distribution of these differences across different years.\nEach box plot provides an overview of how the rainfall disparity between the two seasons varies annually. The x-axis denotes the years, while the y-axis represents the daily rainfall total difference in millimeters.\nThrough these box plots, we aim to elucidate the variability in rainfall disparity over the observed years.\n\nClick to view the code.p_diff_boxplot &lt;- ggplot(data = diff, aes(x = factor(Year), y = Daily_Rainfall_Total_mm)) +\n  geom_boxplot(width = 0.5, fill = \"lightgoldenrod\") +\n  stat_summary(fun = \"median\", geom = \"line\", aes(group = 1), color = \"indianred\", size = 0.8) +  \n  labs(x = \"Year\", y = \"Daily Rainfall Total (mm)\", title = \"Changi: Difference in Rainfall Between Wet and Dry Seasons\") +\n  theme_classic()\n\nggplotly(p_diff_boxplot, tooltip = \"all\")\n\n\n\n\n\nIn the above figure, we’ve added lines connecting the medians for each year’s box plot. These lines exhibit an upward trend, indicating an increasing difference in rainfall over the years.\nThis further supports the earlier prediction that the contrast between the wet months (November to January) and the dry months (February and June to September) is likely to become more pronounced."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-class Exercise 9: Information Dashboard Design",
    "section": "",
    "text": "View the slides to learn more about:"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#tableau",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#tableau",
    "title": "In-class Exercise 9: Information Dashboard Design",
    "section": "1 Tableau",
    "text": "1 Tableau"
  }
]